{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202f318d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch as torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e09000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[‚úì] Project at: c:\\Users\\toby_\\Documents\\TU_Berlin\\Semestre 3\\AMLS\\AMLS_packed\n"
     ]
    }
   ],
   "source": [
    "# Add the project root path if not already present\n",
    "PROJECT_ROOT = os.path.abspath(\"..\")  # move up one level from notebooks/\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "# Visual confirmation\n",
    "print(\"[‚úì] Project at:\", PROJECT_ROOT)\n",
    "\n",
    "from src.data.load_data import load_train_data, EDGCDataset\n",
    "from src.data.stratified_split import stratified_split_pad_torch\n",
    "from src.models.model_trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c79eb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[‚úì] Loaded X_train with 6179 sequences\n",
      "[‚úì] Loaded y_train with shape (6179, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = load_train_data()\n",
    "\n",
    "durations = np.array([len(x) / 300 for x in X_train])\n",
    "\n",
    "cls_count = y_train[0].groupby(y_train[0]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0376f78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5564, 18260]) torch.Size([5564, 1])\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, lengths_train, lengths_val, y_train, y_val = stratified_split_pad_torch(\n",
    "    X_train, y_train\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = EDGCDataset(X_train, lengths_train, y_train)\n",
    "val_dataset = EDGCDataset(X_val, lengths_val, y_val)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d6afc8",
   "metadata": {},
   "source": [
    "# Model Definition\n",
    "\n",
    "## ECGNet Model Architecture (CNN-LSTM model)\n",
    "\n",
    "The `ECGNet` class implements a neural network for ECG signal classification. The architecture consists of:\n",
    "\n",
    "- **Spectrogram transformation**: Converts raw ECG signals into spectrograms using Short-Time Fourier Transform (STFT).\n",
    "- **Convolutional layers**: Two sequential 2D convolutional layers with ReLU activations and max pooling, which extract spatial features from the spectrogram.\n",
    "- **Recurrent layer**: An LSTM layer processes the sequence of features, capturing temporal dependencies.\n",
    "- **Fully connected layer**: The final linear layer maps the LSTM output to the target number of classes.\n",
    "\n",
    "The model expects ECG signals and their lengths as input, and produces class logits for classification tasks.\n",
    "\n",
    "The `ECGNet` class is implemented on the module /models/model_1.py  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e42b209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.model_1 import ECGNet\n",
    "from src.models.hyperparamter_tunning import hyperparameter_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "274ed410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([5564, 18260])\n",
      "lengths_train: torch.Size([5564])\n",
      "y_train: torch.Size([5564, 1])\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"lengths_train: {lengths_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e649ea6",
   "metadata": {},
   "source": [
    "### üîç Hyperparameter Search and Model Selection\n",
    "\n",
    "In this section, we perform **hyperparameter tuning** to improve the performance of our machine learning models.\n",
    "\n",
    "When training neural networks, model performance is highly sensitive to hyperparameters such as the number of layers, hidden units, learning rate, dropout rate, and more. Manually selecting these values is inefficient and often suboptimal. Therefore, we use a **grid search strategy** to systematically explore combinations of hyperparameter values.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚úÖ Why Hyperparameter Tuning?\n",
    "\n",
    "- Different combinations can lead to **very different results**, even with the same architecture.\n",
    "- Some configurations may **overfit** or **underfit**, while others may **generalize better**.\n",
    "- Automated tuning helps us identify the **best performing model** on the validation set without manual trial-and-error.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚öôÔ∏è How it Works\n",
    "\n",
    "1. We define a **search space**, i.e., a dictionary of hyperparameter values to test.\n",
    "2. We generate all **combinations** using Cartesian product (`itertools.product`).\n",
    "3. For each combination:\n",
    "   - Initialize the model with the current hyperparameters.\n",
    "   - Train it for a fixed number of epochs on the training set.\n",
    "   - Evaluate its performance on the validation set using **F1-score** and **loss**.\n",
    "4. Store and compare results, selecting the configuration that performs **best on validation data**.\n",
    "\n",
    "This process is repeated for each of the two model architectures used in this project:\n",
    "\n",
    "- A **CNN-LSTM hybrid** based on time-frequency STFT features.\n",
    "- A **Temporal Convolutional Network (TCN)** using a stacked 1D convolutional architecture.\n",
    "\n",
    "---\n",
    "\n",
    "By applying this strategy, we ensure our final models are both **well-tuned** and **generalizable**, which is essential for real-world performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30f8f656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 32, 'learning_rate': 0.01, 'dropout': 0.1}\n",
      "Epoch 1/7 | Train Loss: 1.0238 | Train F1: 0.1853 | Val Loss: 1.0021 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0173 | Train F1: 0.1853 | Val Loss: 1.0039 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0159 | Train F1: 0.1853 | Val Loss: 1.0058 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0139 | Train F1: 0.1863 | Val Loss: 1.0019 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0156 | Train F1: 0.1853 | Val Loss: 1.0137 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0143 | Train F1: 0.1856 | Val Loss: 0.9956 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0069 | Train F1: 0.1853 | Val Loss: 0.9901 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 32, 'learning_rate': 0.01, 'dropout': 0.2}\n",
      "Epoch 1/7 | Train Loss: 1.0292 | Train F1: 0.1968 | Val Loss: 1.0060 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0208 | Train F1: 0.1853 | Val Loss: 1.0056 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0173 | Train F1: 0.1853 | Val Loss: 1.0049 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0196 | Train F1: 0.1853 | Val Loss: 1.0057 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0170 | Train F1: 0.1853 | Val Loss: 1.0068 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0130 | Train F1: 0.1853 | Val Loss: 1.0091 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0152 | Train F1: 0.1853 | Val Loss: 1.0043 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 32, 'learning_rate': 0.01, 'dropout': 0.5}\n",
      "Epoch 1/7 | Train Loss: 1.0564 | Train F1: 0.1962 | Val Loss: 1.0068 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0344 | Train F1: 0.1879 | Val Loss: 1.0068 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0275 | Train F1: 0.1851 | Val Loss: 1.0242 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0233 | Train F1: 0.1879 | Val Loss: 1.0323 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0234 | Train F1: 0.1866 | Val Loss: 1.0160 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0195 | Train F1: 0.1887 | Val Loss: 1.0050 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0207 | Train F1: 0.1886 | Val Loss: 1.0024 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 32, 'learning_rate': 0.001, 'dropout': 0.1}\n",
      "Epoch 1/7 | Train Loss: 1.0198 | Train F1: 0.2021 | Val Loss: 0.9917 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 0.9948 | Train F1: 0.1898 | Val Loss: 0.9834 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 0.9826 | Train F1: 0.1884 | Val Loss: 0.9539 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 0.9677 | Train F1: 0.1900 | Val Loss: 0.9151 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 0.9181 | Train F1: 0.2462 | Val Loss: 0.9171 | Val F1: 0.3000\n",
      "Epoch 6/7 | Train Loss: 0.8718 | Train F1: 0.2862 | Val Loss: 0.8005 | Val F1: 0.3100\n",
      "Epoch 7/7 | Train Loss: 0.8297 | Train F1: 0.3184 | Val Loss: 0.8373 | Val F1: 0.3090\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 32, 'learning_rate': 0.001, 'dropout': 0.2}\n",
      "Epoch 1/7 | Train Loss: 1.0307 | Train F1: 0.2070 | Val Loss: 0.9798 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0012 | Train F1: 0.1982 | Val Loss: 0.9683 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 0.9908 | Train F1: 0.1966 | Val Loss: 0.9567 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 0.9835 | Train F1: 0.1937 | Val Loss: 0.9596 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 0.9876 | Train F1: 0.1885 | Val Loss: 0.9477 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 0.9823 | Train F1: 0.1989 | Val Loss: 0.9238 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 0.9608 | Train F1: 0.1916 | Val Loss: 0.9504 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 32, 'learning_rate': 0.001, 'dropout': 0.5}\n",
      "Epoch 1/7 | Train Loss: 1.1193 | Train F1: 0.2281 | Val Loss: 1.0068 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0393 | Train F1: 0.1946 | Val Loss: 1.0042 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0238 | Train F1: 0.1860 | Val Loss: 1.0008 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0233 | Train F1: 0.1902 | Val Loss: 0.9892 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0266 | Train F1: 0.1858 | Val Loss: 1.0064 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0169 | Train F1: 0.1853 | Val Loss: 0.9942 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0166 | Train F1: 0.1853 | Val Loss: 0.9983 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 32, 'learning_rate': 0.0005, 'dropout': 0.1}\n",
      "Epoch 1/7 | Train Loss: 1.0291 | Train F1: 0.1943 | Val Loss: 0.9846 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 0.9867 | Train F1: 0.1924 | Val Loss: 0.9472 | Val F1: 0.2216\n",
      "Epoch 3/7 | Train Loss: 0.9650 | Train F1: 0.2076 | Val Loss: 0.9278 | Val F1: 0.2035\n",
      "Epoch 4/7 | Train Loss: 0.9430 | Train F1: 0.2413 | Val Loss: 0.9052 | Val F1: 0.2139\n",
      "Epoch 5/7 | Train Loss: 0.9147 | Train F1: 0.2605 | Val Loss: 0.8478 | Val F1: 0.2911\n",
      "Epoch 6/7 | Train Loss: 0.8625 | Train F1: 0.2956 | Val Loss: 0.7929 | Val F1: 0.3233\n",
      "Epoch 7/7 | Train Loss: 0.8287 | Train F1: 0.3463 | Val Loss: 0.7696 | Val F1: 0.3541\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 32, 'learning_rate': 0.0005, 'dropout': 0.2}\n",
      "Epoch 1/7 | Train Loss: 1.0631 | Train F1: 0.2023 | Val Loss: 0.9948 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0105 | Train F1: 0.1888 | Val Loss: 0.9841 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 0.9904 | Train F1: 0.1882 | Val Loss: 0.9598 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 0.9750 | Train F1: 0.1953 | Val Loss: 0.9161 | Val F1: 0.1855\n",
      "Epoch 5/7 | Train Loss: 0.9463 | Train F1: 0.2260 | Val Loss: 0.9064 | Val F1: 0.2654\n",
      "Epoch 6/7 | Train Loss: 0.9116 | Train F1: 0.2564 | Val Loss: 0.8481 | Val F1: 0.2576\n",
      "Epoch 7/7 | Train Loss: 0.8842 | Train F1: 0.2767 | Val Loss: 0.8177 | Val F1: 0.2680\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 32, 'learning_rate': 0.0005, 'dropout': 0.5}\n",
      "Epoch 1/7 | Train Loss: 1.1384 | Train F1: 0.2336 | Val Loss: 0.9958 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0442 | Train F1: 0.1979 | Val Loss: 1.0018 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0298 | Train F1: 0.1966 | Val Loss: 0.9888 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0262 | Train F1: 0.1896 | Val Loss: 0.9946 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0189 | Train F1: 0.1876 | Val Loss: 0.9893 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0161 | Train F1: 0.1893 | Val Loss: 0.9881 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0100 | Train F1: 0.1855 | Val Loss: 0.9766 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 64, 'learning_rate': 0.01, 'dropout': 0.1}\n",
      "Epoch 1/7 | Train Loss: 1.0277 | Train F1: 0.1879 | Val Loss: 1.0122 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0181 | Train F1: 0.1853 | Val Loss: 1.0087 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0209 | Train F1: 0.1938 | Val Loss: 1.0170 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0183 | Train F1: 0.1853 | Val Loss: 1.0102 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0175 | Train F1: 0.1853 | Val Loss: 1.0159 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0216 | Train F1: 0.1860 | Val Loss: 1.0046 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0158 | Train F1: 0.1853 | Val Loss: 1.0038 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 64, 'learning_rate': 0.01, 'dropout': 0.2}\n",
      "Epoch 1/7 | Train Loss: 1.0313 | Train F1: 0.1891 | Val Loss: 1.0176 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0223 | Train F1: 0.1856 | Val Loss: 1.0044 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0248 | Train F1: 0.1864 | Val Loss: 1.0164 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0208 | Train F1: 0.1852 | Val Loss: 1.0044 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0188 | Train F1: 0.1853 | Val Loss: 1.0049 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0255 | Train F1: 0.1874 | Val Loss: 1.0021 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0218 | Train F1: 0.1852 | Val Loss: 1.0142 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 64, 'learning_rate': 0.01, 'dropout': 0.5}\n",
      "Epoch 1/7 | Train Loss: 1.0562 | Train F1: 0.2017 | Val Loss: 1.0103 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0325 | Train F1: 0.1893 | Val Loss: 1.0074 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0353 | Train F1: 0.1893 | Val Loss: 1.0109 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0332 | Train F1: 0.1924 | Val Loss: 1.0094 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0336 | Train F1: 0.1904 | Val Loss: 1.0049 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0276 | Train F1: 0.1909 | Val Loss: 1.0023 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0263 | Train F1: 0.1912 | Val Loss: 1.0311 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 64, 'learning_rate': 0.001, 'dropout': 0.1}\n",
      "Epoch 1/7 | Train Loss: 1.0032 | Train F1: 0.1935 | Val Loss: 0.9711 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 0.9779 | Train F1: 0.1859 | Val Loss: 0.9356 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 0.9336 | Train F1: 0.2219 | Val Loss: 0.8667 | Val F1: 0.2365\n",
      "Epoch 4/7 | Train Loss: 0.8664 | Train F1: 0.2892 | Val Loss: 0.7887 | Val F1: 0.2984\n",
      "Epoch 5/7 | Train Loss: 0.7994 | Train F1: 0.3591 | Val Loss: 0.7305 | Val F1: 0.3901\n",
      "Epoch 6/7 | Train Loss: 0.7682 | Train F1: 0.4327 | Val Loss: 0.7041 | Val F1: 0.4515\n",
      "Epoch 7/7 | Train Loss: 0.7217 | Train F1: 0.4930 | Val Loss: 0.6518 | Val F1: 0.5566\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 64, 'learning_rate': 0.001, 'dropout': 0.2}\n",
      "Epoch 1/7 | Train Loss: 1.0138 | Train F1: 0.1936 | Val Loss: 0.9748 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 0.9737 | Train F1: 0.1919 | Val Loss: 0.9263 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 0.9478 | Train F1: 0.2064 | Val Loss: 0.8599 | Val F1: 0.2255\n",
      "Epoch 4/7 | Train Loss: 0.8777 | Train F1: 0.2850 | Val Loss: 0.7690 | Val F1: 0.3219\n",
      "Epoch 5/7 | Train Loss: 0.8158 | Train F1: 0.3394 | Val Loss: 0.7190 | Val F1: 0.3279\n",
      "Epoch 6/7 | Train Loss: 0.7643 | Train F1: 0.4262 | Val Loss: 0.6616 | Val F1: 0.5064\n",
      "Epoch 7/7 | Train Loss: 0.7272 | Train F1: 0.5003 | Val Loss: 0.6439 | Val F1: 0.5910\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 64, 'learning_rate': 0.001, 'dropout': 0.5}\n",
      "Epoch 1/7 | Train Loss: 1.0699 | Train F1: 0.2061 | Val Loss: 0.9958 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0260 | Train F1: 0.1930 | Val Loss: 0.9931 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0206 | Train F1: 0.1853 | Val Loss: 0.9975 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0180 | Train F1: 0.1856 | Val Loss: 0.9983 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0189 | Train F1: 0.1856 | Val Loss: 0.9920 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0113 | Train F1: 0.1855 | Val Loss: 0.9919 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0119 | Train F1: 0.1852 | Val Loss: 0.9817 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 64, 'learning_rate': 0.0005, 'dropout': 0.1}\n",
      "Epoch 1/7 | Train Loss: 0.9948 | Train F1: 0.1909 | Val Loss: 0.9587 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 0.9616 | Train F1: 0.2021 | Val Loss: 0.9129 | Val F1: 0.1917\n",
      "Epoch 3/7 | Train Loss: 0.9131 | Train F1: 0.2409 | Val Loss: 0.8392 | Val F1: 0.2464\n",
      "Epoch 4/7 | Train Loss: 0.8497 | Train F1: 0.3155 | Val Loss: 0.7755 | Val F1: 0.3214\n",
      "Epoch 5/7 | Train Loss: 0.8222 | Train F1: 0.3518 | Val Loss: 0.7547 | Val F1: 0.3447\n",
      "Epoch 6/7 | Train Loss: 0.7890 | Train F1: 0.3878 | Val Loss: 0.7318 | Val F1: 0.4145\n",
      "Epoch 7/7 | Train Loss: 0.7674 | Train F1: 0.4662 | Val Loss: 0.7022 | Val F1: 0.4606\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 64, 'learning_rate': 0.0005, 'dropout': 0.2}\n",
      "Epoch 1/7 | Train Loss: 1.0330 | Train F1: 0.2034 | Val Loss: 0.9645 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 0.9881 | Train F1: 0.1930 | Val Loss: 0.9530 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 0.9750 | Train F1: 0.1971 | Val Loss: 0.9493 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 0.9561 | Train F1: 0.2160 | Val Loss: 0.9199 | Val F1: 0.1948\n",
      "Epoch 5/7 | Train Loss: 0.9282 | Train F1: 0.2468 | Val Loss: 0.8654 | Val F1: 0.2427\n",
      "Epoch 6/7 | Train Loss: 0.9081 | Train F1: 0.2665 | Val Loss: 0.8579 | Val F1: 0.2616\n",
      "Epoch 7/7 | Train Loss: 0.8805 | Train F1: 0.3071 | Val Loss: 0.7966 | Val F1: 0.3376\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 64, 'learning_rate': 0.0005, 'dropout': 0.5}\n",
      "Epoch 1/7 | Train Loss: 1.1183 | Train F1: 0.2244 | Val Loss: 0.9767 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0202 | Train F1: 0.1926 | Val Loss: 0.9850 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0128 | Train F1: 0.1877 | Val Loss: 0.9777 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0031 | Train F1: 0.1861 | Val Loss: 0.9672 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0032 | Train F1: 0.1858 | Val Loss: 0.9652 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0040 | Train F1: 0.1909 | Val Loss: 0.9667 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 0.9983 | Train F1: 0.1870 | Val Loss: 0.9566 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 128, 'learning_rate': 0.01, 'dropout': 0.1}\n",
      "Epoch 1/7 | Train Loss: 1.0393 | Train F1: 0.1980 | Val Loss: 1.0121 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0321 | Train F1: 0.1948 | Val Loss: 1.0085 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0316 | Train F1: 0.1944 | Val Loss: 1.0315 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0384 | Train F1: 0.2010 | Val Loss: 1.0027 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0310 | Train F1: 0.1924 | Val Loss: 1.0092 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0263 | Train F1: 0.1900 | Val Loss: 1.0269 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0331 | Train F1: 0.1928 | Val Loss: 1.0397 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 128, 'learning_rate': 0.01, 'dropout': 0.2}\n",
      "Epoch 1/7 | Train Loss: 1.0372 | Train F1: 0.1923 | Val Loss: 1.0267 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0364 | Train F1: 0.1932 | Val Loss: 1.0078 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0362 | Train F1: 0.1941 | Val Loss: 1.0150 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0375 | Train F1: 0.2031 | Val Loss: 1.0031 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0480 | Train F1: 0.2040 | Val Loss: 1.0455 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0306 | Train F1: 0.1875 | Val Loss: 1.0436 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0366 | Train F1: 0.2034 | Val Loss: 1.0590 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 128, 'learning_rate': 0.01, 'dropout': 0.5}\n",
      "Epoch 1/7 | Train Loss: 1.0645 | Train F1: 0.2152 | Val Loss: 1.0048 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0570 | Train F1: 0.2160 | Val Loss: 0.9992 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0600 | Train F1: 0.2126 | Val Loss: 1.0479 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0508 | Train F1: 0.2043 | Val Loss: 1.0051 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0504 | Train F1: 0.1986 | Val Loss: 1.0063 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0420 | Train F1: 0.2075 | Val Loss: 1.0098 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0496 | Train F1: 0.2039 | Val Loss: 1.0114 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 128, 'learning_rate': 0.001, 'dropout': 0.1}\n",
      "Epoch 1/7 | Train Loss: 0.9735 | Train F1: 0.2108 | Val Loss: 0.8985 | Val F1: 0.2275\n",
      "Epoch 2/7 | Train Loss: 0.8612 | Train F1: 0.2993 | Val Loss: 0.7549 | Val F1: 0.3556\n",
      "Epoch 3/7 | Train Loss: 0.7692 | Train F1: 0.4427 | Val Loss: 0.6890 | Val F1: 0.5502\n",
      "Epoch 4/7 | Train Loss: 0.6900 | Train F1: 0.5812 | Val Loss: 0.6430 | Val F1: 0.5484\n",
      "Epoch 5/7 | Train Loss: 0.6457 | Train F1: 0.6176 | Val Loss: 0.6157 | Val F1: 0.5609\n",
      "Epoch 6/7 | Train Loss: 0.6167 | Train F1: 0.6460 | Val Loss: 0.5611 | Val F1: 0.6752\n",
      "Epoch 7/7 | Train Loss: 0.5851 | Train F1: 0.6672 | Val Loss: 0.5687 | Val F1: 0.6609\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 128, 'learning_rate': 0.001, 'dropout': 0.2}\n",
      "Epoch 1/7 | Train Loss: 0.9990 | Train F1: 0.1971 | Val Loss: 0.9510 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 0.9626 | Train F1: 0.2139 | Val Loss: 0.9377 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 0.9546 | Train F1: 0.2304 | Val Loss: 0.9056 | Val F1: 0.2035\n",
      "Epoch 4/7 | Train Loss: 0.8943 | Train F1: 0.2767 | Val Loss: 0.7984 | Val F1: 0.2792\n",
      "Epoch 5/7 | Train Loss: 0.8373 | Train F1: 0.3115 | Val Loss: 0.7356 | Val F1: 0.3366\n",
      "Epoch 6/7 | Train Loss: 0.8007 | Train F1: 0.3827 | Val Loss: 0.7188 | Val F1: 0.3608\n",
      "Epoch 7/7 | Train Loss: 0.7525 | Train F1: 0.4335 | Val Loss: 0.6735 | Val F1: 0.4612\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 128, 'learning_rate': 0.001, 'dropout': 0.5}\n",
      "Epoch 1/7 | Train Loss: 1.0393 | Train F1: 0.2040 | Val Loss: 0.9880 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0156 | Train F1: 0.1899 | Val Loss: 0.9737 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0116 | Train F1: 0.1869 | Val Loss: 0.9841 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0074 | Train F1: 0.1852 | Val Loss: 0.9822 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0029 | Train F1: 0.1853 | Val Loss: 0.9676 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 0.9954 | Train F1: 0.1866 | Val Loss: 0.9751 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0024 | Train F1: 0.1903 | Val Loss: 0.9766 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 128, 'learning_rate': 0.0005, 'dropout': 0.1}\n",
      "Epoch 1/7 | Train Loss: 0.9816 | Train F1: 0.2028 | Val Loss: 0.9131 | Val F1: 0.2031\n",
      "Epoch 2/7 | Train Loss: 0.9116 | Train F1: 0.2569 | Val Loss: 0.8357 | Val F1: 0.3150\n",
      "Epoch 3/7 | Train Loss: 0.8434 | Train F1: 0.3355 | Val Loss: 0.7310 | Val F1: 0.3720\n",
      "Epoch 4/7 | Train Loss: 0.7575 | Train F1: 0.4533 | Val Loss: 0.6785 | Val F1: 0.5061\n",
      "Epoch 5/7 | Train Loss: 0.6998 | Train F1: 0.5465 | Val Loss: 0.6267 | Val F1: 0.6136\n",
      "Epoch 6/7 | Train Loss: 0.6622 | Train F1: 0.5984 | Val Loss: 0.6123 | Val F1: 0.6070\n",
      "Epoch 7/7 | Train Loss: 0.6180 | Train F1: 0.6426 | Val Loss: 0.5819 | Val F1: 0.6389\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 128, 'learning_rate': 0.0005, 'dropout': 0.2}\n",
      "Epoch 1/7 | Train Loss: 1.0094 | Train F1: 0.1915 | Val Loss: 0.9621 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 0.9795 | Train F1: 0.2032 | Val Loss: 0.9411 | Val F1: 0.1998\n",
      "Epoch 3/7 | Train Loss: 0.9599 | Train F1: 0.2191 | Val Loss: 0.9286 | Val F1: 0.2081\n",
      "Epoch 4/7 | Train Loss: 0.9445 | Train F1: 0.2305 | Val Loss: 0.8921 | Val F1: 0.2902\n",
      "Epoch 5/7 | Train Loss: 0.9108 | Train F1: 0.2561 | Val Loss: 0.8493 | Val F1: 0.2578\n",
      "Epoch 6/7 | Train Loss: 0.8729 | Train F1: 0.3035 | Val Loss: 0.7940 | Val F1: 0.3060\n",
      "Epoch 7/7 | Train Loss: 0.8239 | Train F1: 0.3597 | Val Loss: 0.7469 | Val F1: 0.3895\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 128, 'learning_rate': 0.0005, 'dropout': 0.5}\n",
      "Epoch 1/7 | Train Loss: 1.0659 | Train F1: 0.2100 | Val Loss: 0.9972 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0200 | Train F1: 0.1981 | Val Loss: 0.9833 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0120 | Train F1: 0.1888 | Val Loss: 0.9748 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0054 | Train F1: 0.1861 | Val Loss: 0.9666 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 0.9935 | Train F1: 0.1856 | Val Loss: 0.9675 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 0.9922 | Train F1: 0.1871 | Val Loss: 0.9600 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 0.9883 | Train F1: 0.1918 | Val Loss: 0.9502 | Val F1: 0.1856\n",
      "\n",
      "üèÜ Top 3 configurations:\n",
      "\n",
      "#1 - Val F1: 0.6752\n",
      "Hyperparameters:\n",
      "  num_classes: 4\n",
      "  signal_length: 18286\n",
      "  n_fft: 512\n",
      "  hop_length: 256\n",
      "  conv1_padding: 1\n",
      "  conv2_padding: 1\n",
      "  conv1_kernel: 3\n",
      "  conv2_kernel: 3\n",
      "  lstm_num_layers: 1\n",
      "  conv1_channels: 32\n",
      "  conv2_channels: 32\n",
      "  lst_hidden_size: 128\n",
      "  learning_rate: 0.001\n",
      "  dropout: 0.1\n",
      "Train F1: 0.6460 | Val Loss: 0.5611\n",
      "\n",
      "#2 - Val F1: 0.6389\n",
      "Hyperparameters:\n",
      "  num_classes: 4\n",
      "  signal_length: 18286\n",
      "  n_fft: 512\n",
      "  hop_length: 256\n",
      "  conv1_padding: 1\n",
      "  conv2_padding: 1\n",
      "  conv1_kernel: 3\n",
      "  conv2_kernel: 3\n",
      "  lstm_num_layers: 1\n",
      "  conv1_channels: 32\n",
      "  conv2_channels: 32\n",
      "  lst_hidden_size: 128\n",
      "  learning_rate: 0.0005\n",
      "  dropout: 0.1\n",
      "Train F1: 0.6426 | Val Loss: 0.5819\n",
      "\n",
      "#3 - Val F1: 0.5910\n",
      "Hyperparameters:\n",
      "  num_classes: 4\n",
      "  signal_length: 18286\n",
      "  n_fft: 512\n",
      "  hop_length: 256\n",
      "  conv1_padding: 1\n",
      "  conv2_padding: 1\n",
      "  conv1_kernel: 3\n",
      "  conv2_kernel: 3\n",
      "  lstm_num_layers: 1\n",
      "  conv1_channels: 32\n",
      "  conv2_channels: 32\n",
      "  lst_hidden_size: 64\n",
      "  learning_rate: 0.001\n",
      "  dropout: 0.2\n",
      "Train F1: 0.5003 | Val Loss: 0.6439\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "param_grid = {\n",
    "    \"lst_hidden_size\": [32, 64, 128],\n",
    "    \n",
    "    \"learning_rate\": [.01, 0.001, 0.0005],\n",
    "    \n",
    "    \"dropout\": [0.1, 0.2, .5],\n",
    "}\n",
    "fixed = {\n",
    "    \"num_classes\": 4,\n",
    "    \"signal_length\": X_train.shape[1],\n",
    "    \"n_fft\": 512,\n",
    "    \"hop_length\": 256,\n",
    "    \"conv1_padding\": 1,\n",
    "    \"conv2_padding\": 1,\n",
    "    \"conv1_kernel\": 3,\n",
    "    \"conv2_kernel\": 3,\n",
    "    \"lstm_num_layers\": 1,\n",
    "    \"conv1_channels\": 32,\n",
    "    \"conv2_channels\": 32\n",
    "}\n",
    "\n",
    "results = hyperparameter_search(\n",
    "    ECGNet,\n",
    "    param_grid,\n",
    "    fixed,\n",
    "    device=device,\n",
    "    epochs=7,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16745e33",
   "metadata": {},
   "source": [
    "### üß™ Best Hyperparameter Configuration for CNN-LSTM model\n",
    "\n",
    "After performing an extensive grid search over several key hyperparameters of the `CNN-LSTM` architecture, the best-performing configuration (based on validation F1-score) was identified as:\n",
    "\n",
    "- `dropout = .1`\n",
    "- `lst_hidden_size = 128`\n",
    "- `learning_rate = 0.001`\n",
    "\n",
    "This combination yielded the highest balance between training and validation performance, indicating that the model can generalize well without overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ Final Training Setup\n",
    "\n",
    "With the optimal hyperparameters selected, we now proceed to **train the final version of CNN-LSTM** using a larger number of epochs (50) to fully exploit the model's capacity:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "219adc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.9960 - Train F1: 0.1986 - Val Loss: 0.9599 - Val F1: 0.1856\n",
      "Epoch 2/50 - Train Loss: 0.9660 - Train F1: 0.2024 - Val Loss: 0.9607 - Val F1: 0.1856\n",
      "Epoch 3/50 - Train Loss: 0.9492 - Train F1: 0.2190 - Val Loss: 0.8977 - Val F1: 0.2600\n",
      "Epoch 4/50 - Train Loss: 0.8864 - Train F1: 0.2894 - Val Loss: 0.8050 - Val F1: 0.3191\n",
      "Epoch 5/50 - Train Loss: 0.8137 - Train F1: 0.3508 - Val Loss: 0.7638 - Val F1: 0.3429\n",
      "Epoch 6/50 - Train Loss: 0.7776 - Train F1: 0.4056 - Val Loss: 0.7392 - Val F1: 0.3650\n",
      "Epoch 7/50 - Train Loss: 0.7293 - Train F1: 0.4760 - Val Loss: 0.6795 - Val F1: 0.5042\n",
      "Epoch 8/50 - Train Loss: 0.6912 - Train F1: 0.5241 - Val Loss: 0.6486 - Val F1: 0.5731\n",
      "Epoch 9/50 - Train Loss: 0.6588 - Train F1: 0.5856 - Val Loss: 0.6316 - Val F1: 0.5411\n",
      "Epoch 10/50 - Train Loss: 0.6332 - Train F1: 0.6048 - Val Loss: 0.6133 - Val F1: 0.5747\n",
      "Epoch 11/50 - Train Loss: 0.6066 - Train F1: 0.6560 - Val Loss: 0.6072 - Val F1: 0.6544\n",
      "Epoch 12/50 - Train Loss: 0.5907 - Train F1: 0.6483 - Val Loss: 0.5558 - Val F1: 0.6712\n",
      "Epoch 13/50 - Train Loss: 0.5659 - Train F1: 0.6802 - Val Loss: 0.5763 - Val F1: 0.6481\n",
      "Epoch 14/50 - Train Loss: 0.5579 - Train F1: 0.6905 - Val Loss: 0.5421 - Val F1: 0.6894\n",
      "Epoch 15/50 - Train Loss: 0.5352 - Train F1: 0.7060 - Val Loss: 0.5440 - Val F1: 0.6883\n",
      "Epoch 16/50 - Train Loss: 0.5237 - Train F1: 0.7039 - Val Loss: 0.5351 - Val F1: 0.7100\n",
      "Epoch 17/50 - Train Loss: 0.5070 - Train F1: 0.7326 - Val Loss: 0.5371 - Val F1: 0.7136\n",
      "Epoch 18/50 - Train Loss: 0.4963 - Train F1: 0.7395 - Val Loss: 0.5213 - Val F1: 0.6789\n",
      "Epoch 19/50 - Train Loss: 0.4839 - Train F1: 0.7284 - Val Loss: 0.5218 - Val F1: 0.7223\n",
      "Epoch 20/50 - Train Loss: 0.4705 - Train F1: 0.7539 - Val Loss: 0.5169 - Val F1: 0.7562\n",
      "Epoch 21/50 - Train Loss: 0.4647 - Train F1: 0.7604 - Val Loss: 0.5235 - Val F1: 0.7558\n",
      "Epoch 22/50 - Train Loss: 0.4548 - Train F1: 0.7665 - Val Loss: 0.5154 - Val F1: 0.7517\n",
      "Epoch 23/50 - Train Loss: 0.4376 - Train F1: 0.7764 - Val Loss: 0.5234 - Val F1: 0.7395\n",
      "Epoch 24/50 - Train Loss: 0.4232 - Train F1: 0.7900 - Val Loss: 0.5092 - Val F1: 0.7310\n",
      "Epoch 25/50 - Train Loss: 0.4060 - Train F1: 0.7995 - Val Loss: 0.5537 - Val F1: 0.7415\n",
      "Epoch 26/50 - Train Loss: 0.3988 - Train F1: 0.8123 - Val Loss: 0.5388 - Val F1: 0.7419\n",
      "Epoch 27/50 - Train Loss: 0.3705 - Train F1: 0.8176 - Val Loss: 0.5410 - Val F1: 0.7479\n",
      "Epoch 28/50 - Train Loss: 0.3714 - Train F1: 0.8249 - Val Loss: 0.5423 - Val F1: 0.7220\n",
      "Epoch 29/50 - Train Loss: 0.3547 - Train F1: 0.8227 - Val Loss: 0.5594 - Val F1: 0.7356\n",
      "\n",
      "Early stopping triggered at epoch 29\n",
      "0.8873240947723389 0.7356476187705994\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ECGNet(\n",
    "    num_classes=4,\n",
    "    n_fft=512,\n",
    "    hop_length=256,\n",
    "    conv1_padding=1,\n",
    "    conv2_padding=1,\n",
    "    conv1_kernel=3,\n",
    "    conv2_kernel=3,\n",
    "    lstm_num_layers=1,\n",
    "    conv1_channels=32,\n",
    "    conv2_channels=32,\n",
    "    lst_hidden_size=128,\n",
    "    dropout=0.1,\n",
    "    signal_length=X_train.shape[1],\n",
    "    device=device,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "trainer = Trainer(model, optimizer, criterion, augment_data=False, device=device)\n",
    "\n",
    "history = trainer.fit(train_loader, val_loader, epochs=50)\n",
    "\n",
    "train_loss, train_f1 = trainer.evaluate(train_loader)\n",
    "\n",
    "val_loss, val_f1 = trainer.evaluate(val_loader)\n",
    "\n",
    "print(train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6585c602",
   "metadata": {},
   "source": [
    "### üîç Hyperparameter Search and Model Selection (TCN)\n",
    "\n",
    "In this section, we perform **hyperparameter tuning** for the `TCN_STFT_Classifier` model, which combines a Temporal Convolutional Network (TCN). The goal is to identify the best-performing configuration of this architecture on the validation set.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚öôÔ∏è How it Works\n",
    "\n",
    "1. We define a **grid of hyperparameters** to test, including:\n",
    "   - `dropout` rates\n",
    "   - TCN `hidden_channels` per layer\n",
    "   - `kernel size`\n",
    "   - `num levels`\n",
    "2. Using `itertools.product`, we generate all possible **combinations** from this grid.\n",
    "3. For each combination:\n",
    "   - Instantiate the model with the current hyperparameters.\n",
    "   - Train it for a fixed number of epochs (e.g., 10) on the training set.\n",
    "   - Evaluate its performance using **F1-score** and **loss** on the validation set.\n",
    "4. Track the best configuration based on **validation F1-score**.\n",
    "\n",
    "---\n",
    "\n",
    "This tuning process ensures that our TCN model, augmented with time-frequency features from STFT, is both **optimized** and **robust** to overfitting or underfitting. It complements the tuning process performed on our first model (`ECGNet`), allowing us to compare both architectures fairly under their best conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10f232fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'hidden_channels': [64, 128, 128], 'dropout': 0.1, 'num_levels': 3}\n",
      "Learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toby_\\AMLS\\venv\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Train Loss: 0.8957 | Train F1: 0.3041 | Val Loss: 0.7980 | Val F1: 0.4038\n",
      "Epoch 2/5 | Train Loss: 0.7564 | Train F1: 0.4473 | Val Loss: 0.7375 | Val F1: 0.4446\n",
      "Epoch 3/5 | Train Loss: 0.6787 | Train F1: 0.5305 | Val Loss: 0.6653 | Val F1: 0.6193\n",
      "Epoch 4/5 | Train Loss: 0.6359 | Train F1: 0.5815 | Val Loss: 0.6691 | Val F1: 0.5076\n",
      "Epoch 5/5 | Train Loss: 0.6122 | Train F1: 0.5919 | Val Loss: 0.6083 | Val F1: 0.5734\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'hidden_channels': [64, 128, 128, 128], 'dropout': 0.1, 'num_levels': 4}\n",
      "Learning rate: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toby_\\AMLS\\venv\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | Train Loss: 0.9070 | Train F1: 0.2869 | Val Loss: 0.8204 | Val F1: 0.3681\n",
      "Epoch 2/5 | Train Loss: 0.7834 | Train F1: 0.4224 | Val Loss: 0.7378 | Val F1: 0.4814\n",
      "Epoch 3/5 | Train Loss: 0.7238 | Train F1: 0.4984 | Val Loss: 0.6812 | Val F1: 0.5096\n",
      "Epoch 4/5 | Train Loss: 0.6698 | Train F1: 0.5475 | Val Loss: 0.6347 | Val F1: 0.4769\n",
      "Epoch 5/5 | Train Loss: 0.6413 | Train F1: 0.5732 | Val Loss: 0.6350 | Val F1: 0.5744\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'hidden_channels': [64, 128, 128], 'dropout': 0.1, 'num_levels': 3}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 0.9172 | Train F1: 0.2912 | Val Loss: 0.8757 | Val F1: 0.3684\n",
      "Epoch 2/5 | Train Loss: 0.8034 | Train F1: 0.4009 | Val Loss: 0.7960 | Val F1: 0.4224\n",
      "Epoch 3/5 | Train Loss: 0.7169 | Train F1: 0.4890 | Val Loss: 0.6728 | Val F1: 0.5141\n",
      "Epoch 4/5 | Train Loss: 0.6523 | Train F1: 0.5715 | Val Loss: 0.6141 | Val F1: 0.6033\n",
      "Epoch 5/5 | Train Loss: 0.6229 | Train F1: 0.5953 | Val Loss: 0.6177 | Val F1: 0.5955\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'hidden_channels': [64, 128, 128, 128], 'dropout': 0.1, 'num_levels': 4}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 0.9312 | Train F1: 0.2619 | Val Loss: 0.8537 | Val F1: 0.3371\n",
      "Epoch 2/5 | Train Loss: 0.8025 | Train F1: 0.4194 | Val Loss: 0.7514 | Val F1: 0.4283\n",
      "Epoch 3/5 | Train Loss: 0.7157 | Train F1: 0.5299 | Val Loss: 0.7347 | Val F1: 0.4631\n",
      "Epoch 4/5 | Train Loss: 0.6628 | Train F1: 0.5616 | Val Loss: 0.6189 | Val F1: 0.5939\n",
      "Epoch 5/5 | Train Loss: 0.6254 | Train F1: 0.5934 | Val Loss: 0.6146 | Val F1: 0.5390\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'hidden_channels': [64, 128, 128], 'dropout': 0.2, 'num_levels': 3}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 0.8967 | Train F1: 0.3040 | Val Loss: 0.8040 | Val F1: 0.4118\n",
      "Epoch 2/5 | Train Loss: 0.7595 | Train F1: 0.4320 | Val Loss: 0.6950 | Val F1: 0.4264\n",
      "Epoch 3/5 | Train Loss: 0.6987 | Train F1: 0.5022 | Val Loss: 0.6777 | Val F1: 0.5391\n",
      "Epoch 4/5 | Train Loss: 0.6543 | Train F1: 0.5551 | Val Loss: 0.6217 | Val F1: 0.5853\n",
      "Epoch 5/5 | Train Loss: 0.6350 | Train F1: 0.5983 | Val Loss: 0.6618 | Val F1: 0.5545\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'hidden_channels': [64, 128, 128, 128], 'dropout': 0.2, 'num_levels': 4}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 0.9178 | Train F1: 0.2541 | Val Loss: 0.8680 | Val F1: 0.3173\n",
      "Epoch 2/5 | Train Loss: 0.7952 | Train F1: 0.4262 | Val Loss: 0.8095 | Val F1: 0.4508\n",
      "Epoch 3/5 | Train Loss: 0.7308 | Train F1: 0.4912 | Val Loss: 0.6845 | Val F1: 0.5073\n",
      "Epoch 4/5 | Train Loss: 0.6704 | Train F1: 0.5592 | Val Loss: 0.6998 | Val F1: 0.4729\n",
      "Epoch 5/5 | Train Loss: 0.6389 | Train F1: 0.5662 | Val Loss: 0.6300 | Val F1: 0.5820\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'hidden_channels': [64, 128, 128], 'dropout': 0.2, 'num_levels': 3}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 0.9526 | Train F1: 0.2661 | Val Loss: 0.8629 | Val F1: 0.3155\n",
      "Epoch 2/5 | Train Loss: 0.8133 | Train F1: 0.3860 | Val Loss: 0.7584 | Val F1: 0.4543\n",
      "Epoch 3/5 | Train Loss: 0.7664 | Train F1: 0.4611 | Val Loss: 0.7258 | Val F1: 0.4504\n",
      "Epoch 4/5 | Train Loss: 0.6995 | Train F1: 0.5153 | Val Loss: 0.6663 | Val F1: 0.5052\n",
      "Epoch 5/5 | Train Loss: 0.6571 | Train F1: 0.5624 | Val Loss: 0.6697 | Val F1: 0.4931\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'hidden_channels': [64, 128, 128, 128], 'dropout': 0.2, 'num_levels': 4}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 0.9232 | Train F1: 0.2853 | Val Loss: 0.8424 | Val F1: 0.4135\n",
      "Epoch 2/5 | Train Loss: 0.7727 | Train F1: 0.4630 | Val Loss: 0.7353 | Val F1: 0.5212\n",
      "Epoch 3/5 | Train Loss: 0.7223 | Train F1: 0.5295 | Val Loss: 0.6872 | Val F1: 0.4692\n",
      "Epoch 4/5 | Train Loss: 0.6731 | Train F1: 0.5499 | Val Loss: 0.6144 | Val F1: 0.6248\n",
      "Epoch 5/5 | Train Loss: 0.6297 | Train F1: 0.5890 | Val Loss: 0.5849 | Val F1: 0.6317\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'hidden_channels': [64, 128, 128], 'dropout': 0.3, 'num_levels': 3}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 0.9078 | Train F1: 0.2937 | Val Loss: 0.9274 | Val F1: 0.2939\n",
      "Epoch 2/5 | Train Loss: 0.8227 | Train F1: 0.4092 | Val Loss: 0.8512 | Val F1: 0.3397\n",
      "Epoch 3/5 | Train Loss: 0.7520 | Train F1: 0.4835 | Val Loss: 0.7375 | Val F1: 0.4429\n",
      "Epoch 4/5 | Train Loss: 0.7184 | Train F1: 0.5124 | Val Loss: 0.6843 | Val F1: 0.4525\n",
      "Epoch 5/5 | Train Loss: 0.6875 | Train F1: 0.5391 | Val Loss: 0.6628 | Val F1: 0.5620\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'hidden_channels': [64, 128, 128, 128], 'dropout': 0.3, 'num_levels': 4}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 0.9110 | Train F1: 0.2873 | Val Loss: 0.8330 | Val F1: 0.3698\n",
      "Epoch 2/5 | Train Loss: 0.7845 | Train F1: 0.4075 | Val Loss: 0.7812 | Val F1: 0.3652\n",
      "Epoch 3/5 | Train Loss: 0.7108 | Train F1: 0.4814 | Val Loss: 0.6800 | Val F1: 0.4883\n",
      "Epoch 4/5 | Train Loss: 0.6868 | Train F1: 0.5220 | Val Loss: 0.6521 | Val F1: 0.4392\n",
      "Epoch 5/5 | Train Loss: 0.6491 | Train F1: 0.5668 | Val Loss: 0.6985 | Val F1: 0.5298\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'hidden_channels': [64, 128, 128], 'dropout': 0.3, 'num_levels': 3}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 0.9387 | Train F1: 0.2584 | Val Loss: 0.8604 | Val F1: 0.3929\n",
      "Epoch 2/5 | Train Loss: 0.8250 | Train F1: 0.3931 | Val Loss: 0.7924 | Val F1: 0.4902\n",
      "Epoch 3/5 | Train Loss: 0.7698 | Train F1: 0.4746 | Val Loss: 0.7898 | Val F1: 0.5400\n",
      "Epoch 4/5 | Train Loss: 0.7008 | Train F1: 0.5172 | Val Loss: 0.6671 | Val F1: 0.4774\n",
      "Epoch 5/5 | Train Loss: 0.6660 | Train F1: 0.5704 | Val Loss: 0.6403 | Val F1: 0.4913\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'hidden_channels': [64, 128, 128, 128], 'dropout': 0.3, 'num_levels': 4}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 0.9422 | Train F1: 0.2585 | Val Loss: 0.8647 | Val F1: 0.3084\n",
      "Epoch 2/5 | Train Loss: 0.8200 | Train F1: 0.3993 | Val Loss: 0.8141 | Val F1: 0.4274\n",
      "Epoch 3/5 | Train Loss: 0.7506 | Train F1: 0.4777 | Val Loss: 0.7028 | Val F1: 0.4299\n",
      "Epoch 4/5 | Train Loss: 0.6990 | Train F1: 0.5228 | Val Loss: 0.6695 | Val F1: 0.5761\n",
      "Epoch 5/5 | Train Loss: 0.6752 | Train F1: 0.5483 | Val Loss: 0.7029 | Val F1: 0.5054\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'hidden_channels': [128, 128, 128], 'dropout': 0.1, 'num_levels': 3}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 0.9178 | Train F1: 0.3062 | Val Loss: 0.7936 | Val F1: 0.3913\n",
      "Epoch 2/5 | Train Loss: 0.7644 | Train F1: 0.4421 | Val Loss: 0.7232 | Val F1: 0.4500\n",
      "Epoch 3/5 | Train Loss: 0.6881 | Train F1: 0.5132 | Val Loss: 0.7278 | Val F1: 0.4936\n",
      "Epoch 4/5 | Train Loss: 0.6487 | Train F1: 0.5537 | Val Loss: 0.6602 | Val F1: 0.5552\n",
      "Epoch 5/5 | Train Loss: 0.6151 | Train F1: 0.5984 | Val Loss: 0.6149 | Val F1: 0.5873\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'hidden_channels': [128, 128, 128, 128], 'dropout': 0.1, 'num_levels': 4}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 0.9322 | Train F1: 0.3194 | Val Loss: 0.9377 | Val F1: 0.2792\n",
      "Epoch 2/5 | Train Loss: 0.8029 | Train F1: 0.4462 | Val Loss: 0.7147 | Val F1: 0.5170\n",
      "Epoch 3/5 | Train Loss: 0.7109 | Train F1: 0.4914 | Val Loss: 0.6911 | Val F1: 0.5875\n",
      "Epoch 4/5 | Train Loss: 0.6561 | Train F1: 0.5407 | Val Loss: 0.6399 | Val F1: 0.5402\n",
      "Epoch 5/5 | Train Loss: 0.6293 | Train F1: 0.5752 | Val Loss: 0.6340 | Val F1: 0.5842\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'hidden_channels': [128, 128, 128], 'dropout': 0.1, 'num_levels': 3}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 0.9388 | Train F1: 0.3014 | Val Loss: 0.8250 | Val F1: 0.3590\n",
      "Epoch 2/5 | Train Loss: 0.7941 | Train F1: 0.4375 | Val Loss: 0.7554 | Val F1: 0.4329\n",
      "Epoch 3/5 | Train Loss: 0.7277 | Train F1: 0.5123 | Val Loss: 0.7125 | Val F1: 0.5344\n",
      "Epoch 4/5 | Train Loss: 0.6736 | Train F1: 0.5372 | Val Loss: 0.6553 | Val F1: 0.5290\n",
      "Epoch 5/5 | Train Loss: 0.6178 | Train F1: 0.6061 | Val Loss: 0.6421 | Val F1: 0.5283\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'hidden_channels': [128, 128, 128, 128], 'dropout': 0.1, 'num_levels': 4}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 1.0012 | Train F1: 0.2685 | Val Loss: 0.8890 | Val F1: 0.2696\n",
      "Epoch 2/5 | Train Loss: 0.8215 | Train F1: 0.4033 | Val Loss: 0.7766 | Val F1: 0.4729\n",
      "Epoch 3/5 | Train Loss: 0.7611 | Train F1: 0.4493 | Val Loss: 0.7576 | Val F1: 0.4654\n",
      "Epoch 4/5 | Train Loss: 0.6968 | Train F1: 0.5255 | Val Loss: 0.6717 | Val F1: 0.5882\n",
      "Epoch 5/5 | Train Loss: 0.6557 | Train F1: 0.5821 | Val Loss: 0.6524 | Val F1: 0.5759\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'hidden_channels': [128, 128, 128], 'dropout': 0.2, 'num_levels': 3}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 0.9576 | Train F1: 0.2944 | Val Loss: 0.8636 | Val F1: 0.4432\n",
      "Epoch 2/5 | Train Loss: 0.8099 | Train F1: 0.4308 | Val Loss: 0.7688 | Val F1: 0.4124\n",
      "Epoch 3/5 | Train Loss: 0.7408 | Train F1: 0.4911 | Val Loss: 0.7036 | Val F1: 0.4547\n",
      "Epoch 4/5 | Train Loss: 0.6964 | Train F1: 0.5420 | Val Loss: 0.6917 | Val F1: 0.4852\n",
      "Epoch 5/5 | Train Loss: 0.6513 | Train F1: 0.5543 | Val Loss: 0.6419 | Val F1: 0.6107\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'hidden_channels': [128, 128, 128, 128], 'dropout': 0.2, 'num_levels': 4}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 0.9160 | Train F1: 0.3130 | Val Loss: 0.8014 | Val F1: 0.3877\n",
      "Epoch 2/5 | Train Loss: 0.7768 | Train F1: 0.4585 | Val Loss: 0.7542 | Val F1: 0.4746\n",
      "Epoch 3/5 | Train Loss: 0.7098 | Train F1: 0.5104 | Val Loss: 0.7146 | Val F1: 0.4827\n",
      "Epoch 4/5 | Train Loss: 0.6610 | Train F1: 0.5584 | Val Loss: 0.6396 | Val F1: 0.6068\n",
      "Epoch 5/5 | Train Loss: 0.6437 | Train F1: 0.5841 | Val Loss: 0.6175 | Val F1: 0.5325\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'hidden_channels': [128, 128, 128], 'dropout': 0.2, 'num_levels': 3}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 0.9263 | Train F1: 0.3000 | Val Loss: 0.8216 | Val F1: 0.4293\n",
      "Epoch 2/5 | Train Loss: 0.7876 | Train F1: 0.4540 | Val Loss: 0.7569 | Val F1: 0.4162\n",
      "Epoch 3/5 | Train Loss: 0.7180 | Train F1: 0.4909 | Val Loss: 0.6672 | Val F1: 0.5912\n",
      "Epoch 4/5 | Train Loss: 0.6550 | Train F1: 0.5760 | Val Loss: 0.6433 | Val F1: 0.5795\n",
      "Epoch 5/5 | Train Loss: 0.6242 | Train F1: 0.5950 | Val Loss: 0.6487 | Val F1: 0.5243\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'hidden_channels': [128, 128, 128, 128], 'dropout': 0.2, 'num_levels': 4}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 1.0277 | Train F1: 0.2476 | Val Loss: 0.8726 | Val F1: 0.3160\n",
      "Epoch 2/5 | Train Loss: 0.8246 | Train F1: 0.3968 | Val Loss: 0.7716 | Val F1: 0.4529\n",
      "Epoch 3/5 | Train Loss: 0.7660 | Train F1: 0.4768 | Val Loss: 0.8121 | Val F1: 0.4609\n",
      "Epoch 4/5 | Train Loss: 0.7205 | Train F1: 0.5295 | Val Loss: 0.7027 | Val F1: 0.5931\n",
      "Epoch 5/5 | Train Loss: 0.6946 | Train F1: 0.5591 | Val Loss: 0.6829 | Val F1: 0.4902\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'hidden_channels': [128, 128, 128], 'dropout': 0.3, 'num_levels': 3}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 0.9471 | Train F1: 0.2966 | Val Loss: 0.8442 | Val F1: 0.3768\n",
      "Epoch 2/5 | Train Loss: 0.8039 | Train F1: 0.4393 | Val Loss: 0.7625 | Val F1: 0.4620\n",
      "Epoch 3/5 | Train Loss: 0.7531 | Train F1: 0.4875 | Val Loss: 0.7500 | Val F1: 0.4908\n",
      "Epoch 4/5 | Train Loss: 0.6816 | Train F1: 0.5296 | Val Loss: 0.6770 | Val F1: 0.5475\n",
      "Epoch 5/5 | Train Loss: 0.6751 | Train F1: 0.5479 | Val Loss: 0.7081 | Val F1: 0.4993\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'hidden_channels': [128, 128, 128, 128], 'dropout': 0.3, 'num_levels': 4}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 0.9606 | Train F1: 0.2970 | Val Loss: 0.8969 | Val F1: 0.2966\n",
      "Epoch 2/5 | Train Loss: 0.8345 | Train F1: 0.3672 | Val Loss: 0.7790 | Val F1: 0.4139\n",
      "Epoch 3/5 | Train Loss: 0.7586 | Train F1: 0.4757 | Val Loss: 0.7167 | Val F1: 0.5484\n",
      "Epoch 4/5 | Train Loss: 0.7025 | Train F1: 0.5353 | Val Loss: 0.6878 | Val F1: 0.5536\n",
      "Epoch 5/5 | Train Loss: 0.6625 | Train F1: 0.5614 | Val Loss: 0.6267 | Val F1: 0.5827\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'hidden_channels': [128, 128, 128], 'dropout': 0.3, 'num_levels': 3}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 0.9467 | Train F1: 0.2860 | Val Loss: 0.8605 | Val F1: 0.3371\n",
      "Epoch 2/5 | Train Loss: 0.8269 | Train F1: 0.4189 | Val Loss: 0.7650 | Val F1: 0.4295\n",
      "Epoch 3/5 | Train Loss: 0.7427 | Train F1: 0.4883 | Val Loss: 0.7165 | Val F1: 0.5573\n",
      "Epoch 4/5 | Train Loss: 0.6784 | Train F1: 0.5418 | Val Loss: 0.6544 | Val F1: 0.5813\n",
      "Epoch 5/5 | Train Loss: 0.6667 | Train F1: 0.5455 | Val Loss: 0.6449 | Val F1: 0.5685\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'hidden_channels': [128, 128, 128, 128], 'dropout': 0.3, 'num_levels': 4}\n",
      "Learning rate: 0.001\n",
      "Epoch 1/5 | Train Loss: 1.0059 | Train F1: 0.2624 | Val Loss: 0.8881 | Val F1: 0.3419\n",
      "Epoch 2/5 | Train Loss: 0.8281 | Train F1: 0.3978 | Val Loss: 0.8408 | Val F1: 0.3992\n",
      "Epoch 3/5 | Train Loss: 0.7816 | Train F1: 0.4630 | Val Loss: 0.7435 | Val F1: 0.4647\n",
      "Epoch 4/5 | Train Loss: 0.7231 | Train F1: 0.5209 | Val Loss: 0.7178 | Val F1: 0.4822\n",
      "Epoch 5/5 | Train Loss: 0.6937 | Train F1: 0.5381 | Val Loss: 0.6442 | Val F1: 0.5113\n",
      "\n",
      "üèÜ Top 3 configurations:\n",
      "\n",
      "#1 - Val F1: 0.6317 (reached at epoch 5)\n",
      "Hyperparameters:\n",
      "  num_classes: 4\n",
      "  n_fft: 256\n",
      "  hop_length: 128\n",
      "  kernel_size: 5\n",
      "  hidden_channels: [64, 128, 128, 128]\n",
      "  dropout: 0.2\n",
      "  num_levels: 4\n",
      "  learning_rate: 0.001\n",
      "Train F1: 0.5890 | Val Loss: 0.5849\n",
      "\n",
      "#2 - Val F1: 0.6193 (reached at epoch 3)\n",
      "Hyperparameters:\n",
      "  num_classes: 4\n",
      "  n_fft: 256\n",
      "  hop_length: 128\n",
      "  kernel_size: 3\n",
      "  hidden_channels: [64, 128, 128]\n",
      "  dropout: 0.1\n",
      "  num_levels: 3\n",
      "  learning_rate: 0.001\n",
      "Train F1: 0.5305 | Val Loss: 0.6653\n",
      "\n",
      "#3 - Val F1: 0.6107 (reached at epoch 5)\n",
      "Hyperparameters:\n",
      "  num_classes: 4\n",
      "  n_fft: 256\n",
      "  hop_length: 128\n",
      "  kernel_size: 3\n",
      "  hidden_channels: [128, 128, 128]\n",
      "  dropout: 0.2\n",
      "  num_levels: 3\n",
      "  learning_rate: 0.001\n",
      "Train F1: 0.5543 | Val Loss: 0.6419\n"
     ]
    }
   ],
   "source": [
    "from src.models.model_2 import TCN_STFT_Classifier\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    # Configuraciones donde len(hidden_channels) == num_levels\n",
    "    \n",
    "        'hidden_channels': [[64,128,128,128],[128,128,128,128]],\n",
    "    'dropout': [0.1, 0.2, 0.3],\n",
    "    'kernel_size': [3, 5],\n",
    "    'num_levels': [3,4]\n",
    "}\n",
    "\n",
    "\n",
    "fixed = {\n",
    "    \"num_classes\": 4,\n",
    "    \"n_fft\": 256,\n",
    "    \"hop_length\": 128,\n",
    "    \"kernel_size\": 3,\n",
    "    \"learning_rate\" : .001,\n",
    "}\n",
    "\n",
    "results = hyperparameter_search(\n",
    "    TCN_STFT_Classifier,\n",
    "    param_grid,\n",
    "    fixed,\n",
    "    device=device,\n",
    "    epochs=5,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208c4b43",
   "metadata": {},
   "source": [
    "### üèÅ Final Model Selection: (TCN)\n",
    "\n",
    "After conducting an extensive grid search over multiple combinations of hyperparameters, we identified the **best-performing configuration** for the `(TCN)` model.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîß Best Hyperparameters Found\n",
    "\n",
    "- `kernel size = 3`\n",
    "- `num levels = 3`\n",
    "- `dropout = 128`\n",
    "- `hidden channels = [64, 128, 128]`\n",
    "\n",
    "These hyperparameters achieved the **highest F1-score** on the validation set among all tested configurations.\n",
    "\n",
    "---\n",
    "\n",
    "#### üöÄ Final Training Phase\n",
    "\n",
    "Using this optimal setup, we now train the final version of the `TCN` model using **50 epochs** to allow the model to fully converge and leverage the learned configuration. This final model is expected to yield improved generalization performance and serve as a strong baseline for comparison against the first architecture (`CNN_LSTM`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9f03486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toby_\\AMLS\\venv\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.9455 - Train F1: 0.2654 - Val Loss: 0.7854 - Val F1: 0.3621\n",
      "Epoch 2/50 - Train Loss: 0.7761 - Train F1: 0.4506 - Val Loss: 0.7217 - Val F1: 0.5176\n",
      "Epoch 3/50 - Train Loss: 0.7156 - Train F1: 0.4853 - Val Loss: 0.6634 - Val F1: 0.5686\n",
      "Epoch 4/50 - Train Loss: 0.6795 - Train F1: 0.5269 - Val Loss: 0.6553 - Val F1: 0.5142\n",
      "Epoch 5/50 - Train Loss: 0.6405 - Train F1: 0.5714 - Val Loss: 0.6434 - Val F1: 0.4684\n",
      "Epoch 6/50 - Train Loss: 0.6368 - Train F1: 0.5711 - Val Loss: 0.6879 - Val F1: 0.5538\n",
      "Epoch 7/50 - Train Loss: 0.6140 - Train F1: 0.5873 - Val Loss: 0.6863 - Val F1: 0.4769\n",
      "Epoch 8/50 - Train Loss: 0.5865 - Train F1: 0.6157 - Val Loss: 0.6351 - Val F1: 0.4949\n",
      "Epoch 9/50 - Train Loss: 0.5819 - Train F1: 0.6471 - Val Loss: 0.5858 - Val F1: 0.6015\n",
      "Epoch 10/50 - Train Loss: 0.5536 - Train F1: 0.6607 - Val Loss: 0.5457 - Val F1: 0.6634\n",
      "Epoch 11/50 - Train Loss: 0.5548 - Train F1: 0.6483 - Val Loss: 0.5744 - Val F1: 0.5991\n",
      "Epoch 12/50 - Train Loss: 0.5391 - Train F1: 0.6626 - Val Loss: 0.5687 - Val F1: 0.6919\n",
      "Epoch 13/50 - Train Loss: 0.5326 - Train F1: 0.6827 - Val Loss: 0.5570 - Val F1: 0.6309\n",
      "Epoch 14/50 - Train Loss: 0.5125 - Train F1: 0.6959 - Val Loss: 0.5753 - Val F1: 0.6783\n",
      "Epoch 15/50 - Train Loss: 0.4959 - Train F1: 0.7092 - Val Loss: 0.5894 - Val F1: 0.6601\n",
      "\n",
      "Early stopping triggered at epoch 15\n",
      "0.7149182558059692 0.6601388454437256\n"
     ]
    }
   ],
   "source": [
    "from src.models.model_2 import TCN_STFT_Classifier\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = TCN_STFT_Classifier(\n",
    "    num_classes=4,\n",
    "    hop_length = 128,\n",
    "    n_fft = 256,\n",
    "    kernel_size = 3, \n",
    "    hidden_channels=  [64, 128, 128],\n",
    "    dropout = 0.2,\n",
    "    num_levels = 3,\n",
    "    device=device,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "trainer = Trainer(model, optimizer, criterion, augment_data=False, device=device)\n",
    "\n",
    "history = trainer.fit(train_loader, val_loader, epochs=50)\n",
    "\n",
    "train_loss, train_f1 = trainer.evaluate(train_loader)\n",
    "\n",
    "val_loss, val_f1 = trainer.evaluate(val_loader)\n",
    "\n",
    "print(train_f1, val_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d0490b",
   "metadata": {},
   "source": [
    "## Lets use augment data for improving performance of the model training. First with ECG architechture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "236e30da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 32, 'learning_rate': 0.01, 'dropout': 0.1}\n",
      "Epoch 1/7 | Train Loss: 1.0292 | Train F1: 0.1876 | Val Loss: 1.0027 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0173 | Train F1: 0.1856 | Val Loss: 1.0097 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0164 | Train F1: 0.1853 | Val Loss: 1.0110 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0150 | Train F1: 0.1856 | Val Loss: 1.0059 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0131 | Train F1: 0.1853 | Val Loss: 1.0083 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0150 | Train F1: 0.1853 | Val Loss: 1.0042 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0169 | Train F1: 0.1853 | Val Loss: 1.0052 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 32, 'learning_rate': 0.01, 'dropout': 0.2}\n",
      "Epoch 1/7 | Train Loss: 1.0277 | Train F1: 0.1863 | Val Loss: 1.0042 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0171 | Train F1: 0.1853 | Val Loss: 1.0048 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0238 | Train F1: 0.1853 | Val Loss: 1.0107 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0166 | Train F1: 0.1874 | Val Loss: 1.0214 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0188 | Train F1: 0.1852 | Val Loss: 1.0063 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0180 | Train F1: 0.1853 | Val Loss: 1.0085 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0159 | Train F1: 0.1853 | Val Loss: 1.0076 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 32, 'learning_rate': 0.01, 'dropout': 0.5}\n",
      "Epoch 1/7 | Train Loss: 1.0497 | Train F1: 0.1963 | Val Loss: 1.0035 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0376 | Train F1: 0.1904 | Val Loss: 1.0125 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0240 | Train F1: 0.1876 | Val Loss: 1.0094 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0276 | Train F1: 0.1887 | Val Loss: 1.0080 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0234 | Train F1: 0.1915 | Val Loss: 1.0138 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0259 | Train F1: 0.1876 | Val Loss: 1.0123 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0234 | Train F1: 0.1859 | Val Loss: 1.0109 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 32, 'learning_rate': 0.001, 'dropout': 0.1}\n",
      "Epoch 1/7 | Train Loss: 1.0212 | Train F1: 0.2025 | Val Loss: 0.9834 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 0.9848 | Train F1: 0.1866 | Val Loss: 0.9539 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 0.9692 | Train F1: 0.2012 | Val Loss: 0.9546 | Val F1: 0.2086\n",
      "Epoch 4/7 | Train Loss: 0.9456 | Train F1: 0.2330 | Val Loss: 0.9144 | Val F1: 0.2064\n",
      "Epoch 5/7 | Train Loss: 0.9045 | Train F1: 0.2561 | Val Loss: 0.8391 | Val F1: 0.2765\n",
      "Epoch 6/7 | Train Loss: 0.8504 | Train F1: 0.3145 | Val Loss: 0.7955 | Val F1: 0.3349\n",
      "Epoch 7/7 | Train Loss: 0.8092 | Train F1: 0.3721 | Val Loss: 0.7819 | Val F1: 0.3594\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 32, 'learning_rate': 0.001, 'dropout': 0.2}\n",
      "Epoch 1/7 | Train Loss: 1.0383 | Train F1: 0.2019 | Val Loss: 0.9799 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 0.9957 | Train F1: 0.1912 | Val Loss: 0.9796 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 0.9787 | Train F1: 0.1965 | Val Loss: 0.9571 | Val F1: 0.2071\n",
      "Epoch 4/7 | Train Loss: 0.9691 | Train F1: 0.2168 | Val Loss: 0.9225 | Val F1: 0.2435\n",
      "Epoch 5/7 | Train Loss: 0.9514 | Train F1: 0.2385 | Val Loss: 0.8925 | Val F1: 0.2541\n",
      "Epoch 6/7 | Train Loss: 0.9137 | Train F1: 0.2689 | Val Loss: 0.8671 | Val F1: 0.2647\n",
      "Epoch 7/7 | Train Loss: 0.8928 | Train F1: 0.2773 | Val Loss: 0.8481 | Val F1: 0.2838\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 32, 'learning_rate': 0.001, 'dropout': 0.5}\n",
      "Epoch 1/7 | Train Loss: 1.1368 | Train F1: 0.2244 | Val Loss: 0.9843 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0404 | Train F1: 0.1973 | Val Loss: 1.0009 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0270 | Train F1: 0.1871 | Val Loss: 1.0007 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0214 | Train F1: 0.1856 | Val Loss: 0.9981 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0187 | Train F1: 0.1859 | Val Loss: 0.9981 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0152 | Train F1: 0.1856 | Val Loss: 0.9901 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0174 | Train F1: 0.1856 | Val Loss: 0.9986 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 32, 'learning_rate': 0.0005, 'dropout': 0.1}\n",
      "Epoch 1/7 | Train Loss: 1.0650 | Train F1: 0.2077 | Val Loss: 0.9796 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 0.9808 | Train F1: 0.1901 | Val Loss: 0.9549 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 0.9676 | Train F1: 0.2011 | Val Loss: 0.9198 | Val F1: 0.2074\n",
      "Epoch 4/7 | Train Loss: 0.9482 | Train F1: 0.2190 | Val Loss: 0.8989 | Val F1: 0.2491\n",
      "Epoch 5/7 | Train Loss: 0.9102 | Train F1: 0.2587 | Val Loss: 0.8469 | Val F1: 0.3133\n",
      "Epoch 6/7 | Train Loss: 0.8771 | Train F1: 0.3012 | Val Loss: 0.8125 | Val F1: 0.2937\n",
      "Epoch 7/7 | Train Loss: 0.8482 | Train F1: 0.3232 | Val Loss: 0.8028 | Val F1: 0.3581\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 32, 'learning_rate': 0.0005, 'dropout': 0.2}\n",
      "Epoch 1/7 | Train Loss: 1.0677 | Train F1: 0.2004 | Val Loss: 0.9967 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 0.9965 | Train F1: 0.1975 | Val Loss: 0.9620 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 0.9799 | Train F1: 0.2042 | Val Loss: 0.9259 | Val F1: 0.2037\n",
      "Epoch 4/7 | Train Loss: 0.9552 | Train F1: 0.2305 | Val Loss: 0.8911 | Val F1: 0.2288\n",
      "Epoch 5/7 | Train Loss: 0.9279 | Train F1: 0.2453 | Val Loss: 0.8495 | Val F1: 0.2544\n",
      "Epoch 6/7 | Train Loss: 0.8773 | Train F1: 0.2835 | Val Loss: 0.8238 | Val F1: 0.2720\n",
      "Epoch 7/7 | Train Loss: 0.8509 | Train F1: 0.3080 | Val Loss: 0.7861 | Val F1: 0.3267\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 32, 'learning_rate': 0.0005, 'dropout': 0.5}\n",
      "Epoch 1/7 | Train Loss: 1.1564 | Train F1: 0.2127 | Val Loss: 0.9995 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0465 | Train F1: 0.1979 | Val Loss: 0.9909 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0333 | Train F1: 0.1916 | Val Loss: 0.9958 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0247 | Train F1: 0.1875 | Val Loss: 0.9897 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0187 | Train F1: 0.1879 | Val Loss: 0.9936 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0166 | Train F1: 0.1904 | Val Loss: 0.9815 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0083 | Train F1: 0.1859 | Val Loss: 0.9825 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 64, 'learning_rate': 0.01, 'dropout': 0.1}\n",
      "Epoch 1/7 | Train Loss: 1.0246 | Train F1: 0.1866 | Val Loss: 1.0197 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0184 | Train F1: 0.1853 | Val Loss: 1.0221 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0207 | Train F1: 0.1853 | Val Loss: 1.0079 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0192 | Train F1: 0.1852 | Val Loss: 1.0147 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0234 | Train F1: 0.1858 | Val Loss: 1.0271 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0213 | Train F1: 0.1860 | Val Loss: 1.0184 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0267 | Train F1: 0.1856 | Val Loss: 1.0136 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 64, 'learning_rate': 0.01, 'dropout': 0.2}\n",
      "Epoch 1/7 | Train Loss: 1.0282 | Train F1: 0.1890 | Val Loss: 1.0228 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0209 | Train F1: 0.1852 | Val Loss: 1.0155 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0235 | Train F1: 0.1892 | Val Loss: 1.0080 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0231 | Train F1: 0.1879 | Val Loss: 1.0049 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0202 | Train F1: 0.1864 | Val Loss: 1.0087 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0247 | Train F1: 0.1852 | Val Loss: 1.0041 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0219 | Train F1: 0.1859 | Val Loss: 1.0158 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 64, 'learning_rate': 0.01, 'dropout': 0.5}\n",
      "Epoch 1/7 | Train Loss: 1.0491 | Train F1: 0.1990 | Val Loss: 1.0368 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0387 | Train F1: 0.1933 | Val Loss: 1.0051 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0322 | Train F1: 0.1935 | Val Loss: 1.0293 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0285 | Train F1: 0.1997 | Val Loss: 1.0057 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0292 | Train F1: 0.1926 | Val Loss: 1.0060 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0294 | Train F1: 0.1978 | Val Loss: 1.0137 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0280 | Train F1: 0.1880 | Val Loss: 1.0060 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 64, 'learning_rate': 0.001, 'dropout': 0.1}\n",
      "Epoch 1/7 | Train Loss: 0.9963 | Train F1: 0.1915 | Val Loss: 0.9657 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 0.9815 | Train F1: 0.1865 | Val Loss: 0.9662 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 0.9741 | Train F1: 0.1873 | Val Loss: 0.9474 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 0.9348 | Train F1: 0.2066 | Val Loss: 0.8691 | Val F1: 0.2280\n",
      "Epoch 5/7 | Train Loss: 0.8680 | Train F1: 0.3039 | Val Loss: 0.8032 | Val F1: 0.3180\n",
      "Epoch 6/7 | Train Loss: 0.8223 | Train F1: 0.3903 | Val Loss: 0.7644 | Val F1: 0.3557\n",
      "Epoch 7/7 | Train Loss: 0.7968 | Train F1: 0.4183 | Val Loss: 0.7484 | Val F1: 0.3413\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 64, 'learning_rate': 0.001, 'dropout': 0.2}\n",
      "Epoch 1/7 | Train Loss: 1.0174 | Train F1: 0.1870 | Val Loss: 0.9702 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 0.9903 | Train F1: 0.1880 | Val Loss: 0.9528 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 0.9698 | Train F1: 0.1903 | Val Loss: 0.9386 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 0.9214 | Train F1: 0.2313 | Val Loss: 0.8557 | Val F1: 0.2562\n",
      "Epoch 5/7 | Train Loss: 0.8802 | Train F1: 0.2779 | Val Loss: 0.8209 | Val F1: 0.2828\n",
      "Epoch 6/7 | Train Loss: 0.8404 | Train F1: 0.3556 | Val Loss: 0.7734 | Val F1: 0.4398\n",
      "Epoch 7/7 | Train Loss: 0.7984 | Train F1: 0.4203 | Val Loss: 0.7622 | Val F1: 0.4251\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 64, 'learning_rate': 0.001, 'dropout': 0.5}\n",
      "Epoch 1/7 | Train Loss: 1.0788 | Train F1: 0.2029 | Val Loss: 1.0028 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0229 | Train F1: 0.1903 | Val Loss: 0.9988 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0135 | Train F1: 0.1859 | Val Loss: 0.9972 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0126 | Train F1: 0.1852 | Val Loss: 0.9880 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0077 | Train F1: 0.1855 | Val Loss: 0.9884 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0076 | Train F1: 0.1852 | Val Loss: 0.9895 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0041 | Train F1: 0.1853 | Val Loss: 0.9830 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 64, 'learning_rate': 0.0005, 'dropout': 0.1}\n",
      "Epoch 1/7 | Train Loss: 1.0026 | Train F1: 0.2121 | Val Loss: 0.9429 | Val F1: 0.2166\n",
      "Epoch 2/7 | Train Loss: 0.9526 | Train F1: 0.2191 | Val Loss: 0.9072 | Val F1: 0.2475\n",
      "Epoch 3/7 | Train Loss: 0.9003 | Train F1: 0.2715 | Val Loss: 0.8705 | Val F1: 0.2304\n",
      "Epoch 4/7 | Train Loss: 0.8399 | Train F1: 0.3316 | Val Loss: 0.7988 | Val F1: 0.2727\n",
      "Epoch 5/7 | Train Loss: 0.8026 | Train F1: 0.4199 | Val Loss: 0.7497 | Val F1: 0.5582\n",
      "Epoch 6/7 | Train Loss: 0.7651 | Train F1: 0.4842 | Val Loss: 0.7307 | Val F1: 0.4651\n",
      "Epoch 7/7 | Train Loss: 0.7333 | Train F1: 0.5315 | Val Loss: 0.6918 | Val F1: 0.5650\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 64, 'learning_rate': 0.0005, 'dropout': 0.2}\n",
      "Epoch 1/7 | Train Loss: 1.0105 | Train F1: 0.2078 | Val Loss: 0.9578 | Val F1: 0.1886\n",
      "Epoch 2/7 | Train Loss: 0.9799 | Train F1: 0.1971 | Val Loss: 0.9451 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 0.9689 | Train F1: 0.2029 | Val Loss: 0.9463 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 0.9566 | Train F1: 0.2105 | Val Loss: 0.9204 | Val F1: 0.1997\n",
      "Epoch 5/7 | Train Loss: 0.9438 | Train F1: 0.2457 | Val Loss: 0.8969 | Val F1: 0.2797\n",
      "Epoch 6/7 | Train Loss: 0.9198 | Train F1: 0.2627 | Val Loss: 0.8695 | Val F1: 0.2472\n",
      "Epoch 7/7 | Train Loss: 0.8927 | Train F1: 0.2851 | Val Loss: 0.8360 | Val F1: 0.2869\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 64, 'learning_rate': 0.0005, 'dropout': 0.5}\n",
      "Epoch 1/7 | Train Loss: 1.0898 | Train F1: 0.2254 | Val Loss: 1.0097 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0288 | Train F1: 0.1933 | Val Loss: 0.9891 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0194 | Train F1: 0.1875 | Val Loss: 0.9934 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0110 | Train F1: 0.1882 | Val Loss: 0.9859 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0136 | Train F1: 0.1852 | Val Loss: 0.9802 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0011 | Train F1: 0.1885 | Val Loss: 0.9725 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0073 | Train F1: 0.1883 | Val Loss: 0.9632 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 128, 'learning_rate': 0.01, 'dropout': 0.1}\n",
      "Epoch 1/7 | Train Loss: 1.0378 | Train F1: 0.1959 | Val Loss: 1.0051 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0324 | Train F1: 0.1951 | Val Loss: 1.0423 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0308 | Train F1: 0.2040 | Val Loss: 1.0303 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0388 | Train F1: 0.1962 | Val Loss: 1.0132 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0385 | Train F1: 0.1934 | Val Loss: 1.0107 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0299 | Train F1: 0.2010 | Val Loss: 1.0514 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0373 | Train F1: 0.1976 | Val Loss: 1.0242 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 128, 'learning_rate': 0.01, 'dropout': 0.2}\n",
      "Epoch 1/7 | Train Loss: 1.0512 | Train F1: 0.2040 | Val Loss: 1.0078 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0361 | Train F1: 0.1975 | Val Loss: 1.0268 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0441 | Train F1: 0.2079 | Val Loss: 1.0385 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0336 | Train F1: 0.1992 | Val Loss: 1.0064 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0396 | Train F1: 0.1998 | Val Loss: 1.0073 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0440 | Train F1: 0.2092 | Val Loss: 1.0111 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0387 | Train F1: 0.1928 | Val Loss: 1.0422 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 128, 'learning_rate': 0.01, 'dropout': 0.5}\n",
      "Epoch 1/7 | Train Loss: 1.0715 | Train F1: 0.2197 | Val Loss: 1.0253 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0642 | Train F1: 0.2140 | Val Loss: 1.0229 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0580 | Train F1: 0.2090 | Val Loss: 1.0024 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0531 | Train F1: 0.2103 | Val Loss: 1.0267 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 1.0479 | Train F1: 0.2116 | Val Loss: 0.9984 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 1.0567 | Train F1: 0.2099 | Val Loss: 1.0103 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 1.0518 | Train F1: 0.2050 | Val Loss: 1.0143 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 128, 'learning_rate': 0.001, 'dropout': 0.1}\n",
      "Epoch 1/7 | Train Loss: 0.9682 | Train F1: 0.2214 | Val Loss: 0.9204 | Val F1: 0.3024\n",
      "Epoch 2/7 | Train Loss: 0.8493 | Train F1: 0.3266 | Val Loss: 0.7780 | Val F1: 0.3450\n",
      "Epoch 3/7 | Train Loss: 0.7550 | Train F1: 0.4590 | Val Loss: 0.6991 | Val F1: 0.5252\n",
      "Epoch 4/7 | Train Loss: 0.7067 | Train F1: 0.5389 | Val Loss: 0.6651 | Val F1: 0.6386\n",
      "Epoch 5/7 | Train Loss: 0.6483 | Train F1: 0.6135 | Val Loss: 0.6331 | Val F1: 0.6519\n",
      "Epoch 6/7 | Train Loss: 0.6324 | Train F1: 0.6326 | Val Loss: 0.5921 | Val F1: 0.6809\n",
      "Epoch 7/7 | Train Loss: 0.6044 | Train F1: 0.6622 | Val Loss: 0.5770 | Val F1: 0.6984\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 128, 'learning_rate': 0.001, 'dropout': 0.2}\n",
      "Epoch 1/7 | Train Loss: 1.0035 | Train F1: 0.1902 | Val Loss: 0.9738 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 0.9737 | Train F1: 0.1902 | Val Loss: 0.9442 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 0.9583 | Train F1: 0.2019 | Val Loss: 0.8996 | Val F1: 0.2122\n",
      "Epoch 4/7 | Train Loss: 0.9183 | Train F1: 0.2556 | Val Loss: 0.8308 | Val F1: 0.3074\n",
      "Epoch 5/7 | Train Loss: 0.8607 | Train F1: 0.3095 | Val Loss: 0.8073 | Val F1: 0.3212\n",
      "Epoch 6/7 | Train Loss: 0.8206 | Train F1: 0.3400 | Val Loss: 0.7618 | Val F1: 0.3551\n",
      "Epoch 7/7 | Train Loss: 0.7820 | Train F1: 0.4139 | Val Loss: 0.7339 | Val F1: 0.3807\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 128, 'learning_rate': 0.001, 'dropout': 0.5}\n",
      "Epoch 1/7 | Train Loss: 1.0478 | Train F1: 0.1991 | Val Loss: 0.9918 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0089 | Train F1: 0.1951 | Val Loss: 0.9849 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0082 | Train F1: 0.1875 | Val Loss: 0.9808 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0005 | Train F1: 0.1861 | Val Loss: 0.9688 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 0.9998 | Train F1: 0.1867 | Val Loss: 0.9759 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 0.9998 | Train F1: 0.1870 | Val Loss: 0.9705 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 0.9957 | Train F1: 0.1856 | Val Loss: 0.9639 | Val F1: 0.1856\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 128, 'learning_rate': 0.0005, 'dropout': 0.1}\n",
      "Epoch 1/7 | Train Loss: 0.9996 | Train F1: 0.1966 | Val Loss: 0.9524 | Val F1: 0.1883\n",
      "Epoch 2/7 | Train Loss: 0.9630 | Train F1: 0.2045 | Val Loss: 0.9400 | Val F1: 0.1886\n",
      "Epoch 3/7 | Train Loss: 0.9438 | Train F1: 0.2154 | Val Loss: 0.9037 | Val F1: 0.2425\n",
      "Epoch 4/7 | Train Loss: 0.9174 | Train F1: 0.2470 | Val Loss: 0.8661 | Val F1: 0.3134\n",
      "Epoch 5/7 | Train Loss: 0.8673 | Train F1: 0.3028 | Val Loss: 0.8205 | Val F1: 0.2918\n",
      "Epoch 6/7 | Train Loss: 0.8223 | Train F1: 0.3701 | Val Loss: 0.7728 | Val F1: 0.4452\n",
      "Epoch 7/7 | Train Loss: 0.7896 | Train F1: 0.4204 | Val Loss: 0.7489 | Val F1: 0.4590\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 128, 'learning_rate': 0.0005, 'dropout': 0.2}\n",
      "Epoch 1/7 | Train Loss: 0.9985 | Train F1: 0.2041 | Val Loss: 0.9346 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 0.9687 | Train F1: 0.2018 | Val Loss: 0.9139 | Val F1: 0.2064\n",
      "Epoch 3/7 | Train Loss: 0.9405 | Train F1: 0.2440 | Val Loss: 0.8779 | Val F1: 0.2570\n",
      "Epoch 4/7 | Train Loss: 0.9155 | Train F1: 0.2715 | Val Loss: 0.8330 | Val F1: 0.2916\n",
      "Epoch 5/7 | Train Loss: 0.8512 | Train F1: 0.3267 | Val Loss: 0.7686 | Val F1: 0.4398\n",
      "Epoch 6/7 | Train Loss: 0.8049 | Train F1: 0.4172 | Val Loss: 0.7432 | Val F1: 0.4482\n",
      "Epoch 7/7 | Train Loss: 0.7771 | Train F1: 0.4733 | Val Loss: 0.7193 | Val F1: 0.4759\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'signal_length': 18286, 'n_fft': 512, 'hop_length': 256, 'conv1_padding': 1, 'conv2_padding': 1, 'conv1_kernel': 3, 'conv2_kernel': 3, 'lstm_num_layers': 1, 'conv1_channels': 32, 'conv2_channels': 32, 'lst_hidden_size': 128, 'learning_rate': 0.0005, 'dropout': 0.5}\n",
      "Epoch 1/7 | Train Loss: 1.0565 | Train F1: 0.2176 | Val Loss: 0.9968 | Val F1: 0.1856\n",
      "Epoch 2/7 | Train Loss: 1.0101 | Train F1: 0.1946 | Val Loss: 0.9696 | Val F1: 0.1856\n",
      "Epoch 3/7 | Train Loss: 1.0013 | Train F1: 0.1899 | Val Loss: 0.9693 | Val F1: 0.1856\n",
      "Epoch 4/7 | Train Loss: 1.0035 | Train F1: 0.1888 | Val Loss: 0.9753 | Val F1: 0.1856\n",
      "Epoch 5/7 | Train Loss: 0.9936 | Train F1: 0.1897 | Val Loss: 0.9578 | Val F1: 0.1856\n",
      "Epoch 6/7 | Train Loss: 0.9890 | Train F1: 0.1910 | Val Loss: 0.9498 | Val F1: 0.1856\n",
      "Epoch 7/7 | Train Loss: 0.9862 | Train F1: 0.1945 | Val Loss: 0.9462 | Val F1: 0.1856\n",
      "\n",
      "üèÜ Top 3 configurations:\n",
      "\n",
      "#1 - Val F1: 0.6984\n",
      "Hyperparameters:\n",
      "  num_classes: 4\n",
      "  signal_length: 18286\n",
      "  n_fft: 512\n",
      "  hop_length: 256\n",
      "  conv1_padding: 1\n",
      "  conv2_padding: 1\n",
      "  conv1_kernel: 3\n",
      "  conv2_kernel: 3\n",
      "  lstm_num_layers: 1\n",
      "  conv1_channels: 32\n",
      "  conv2_channels: 32\n",
      "  lst_hidden_size: 128\n",
      "  learning_rate: 0.001\n",
      "  dropout: 0.1\n",
      "Train F1: 0.6622 | Val Loss: 0.5770\n",
      "\n",
      "#2 - Val F1: 0.5650\n",
      "Hyperparameters:\n",
      "  num_classes: 4\n",
      "  signal_length: 18286\n",
      "  n_fft: 512\n",
      "  hop_length: 256\n",
      "  conv1_padding: 1\n",
      "  conv2_padding: 1\n",
      "  conv1_kernel: 3\n",
      "  conv2_kernel: 3\n",
      "  lstm_num_layers: 1\n",
      "  conv1_channels: 32\n",
      "  conv2_channels: 32\n",
      "  lst_hidden_size: 64\n",
      "  learning_rate: 0.0005\n",
      "  dropout: 0.1\n",
      "Train F1: 0.5315 | Val Loss: 0.6918\n",
      "\n",
      "#3 - Val F1: 0.4759\n",
      "Hyperparameters:\n",
      "  num_classes: 4\n",
      "  signal_length: 18286\n",
      "  n_fft: 512\n",
      "  hop_length: 256\n",
      "  conv1_padding: 1\n",
      "  conv2_padding: 1\n",
      "  conv1_kernel: 3\n",
      "  conv2_kernel: 3\n",
      "  lstm_num_layers: 1\n",
      "  conv1_channels: 32\n",
      "  conv2_channels: 32\n",
      "  lst_hidden_size: 128\n",
      "  learning_rate: 0.0005\n",
      "  dropout: 0.2\n",
      "Train F1: 0.4733 | Val Loss: 0.7193\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "param_grid = {\n",
    "    \"lst_hidden_size\": [32, 64, 128],\n",
    "    \n",
    "    \"learning_rate\": [.01, 0.001, 0.0005],\n",
    "    \n",
    "    \"dropout\": [0.1, 0.2, .5],\n",
    "}\n",
    "fixed = {\n",
    "    \"num_classes\": 4,\n",
    "    \"signal_length\": X_train.shape[1],\n",
    "    \"n_fft\": 512,\n",
    "    \"hop_length\": 256,\n",
    "    \"conv1_padding\": 1,\n",
    "    \"conv2_padding\": 1,\n",
    "    \"conv1_kernel\": 3,\n",
    "    \"conv2_kernel\": 3,\n",
    "    \"lstm_num_layers\": 1,\n",
    "    \"conv1_channels\": 32,\n",
    "    \"conv2_channels\": 32\n",
    "}\n",
    "\n",
    "results = hyperparameter_search(\n",
    "    ECGNet,\n",
    "    param_grid,\n",
    "    fixed,\n",
    "    device=device,\n",
    "    epochs=7,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    augmented_data = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459218b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.9813 - Train F1: 0.1947 - Val Loss: 0.9244 - Val F1: 0.2064\n",
      "Epoch 2/50 - Train Loss: 0.9182 - Train F1: 0.2427 - Val Loss: 0.8393 - Val F1: 0.2887\n",
      "Epoch 3/50 - Train Loss: 0.8469 - Train F1: 0.3063 - Val Loss: 0.7759 - Val F1: 0.3293\n",
      "Epoch 4/50 - Train Loss: 0.7960 - Train F1: 0.3824 - Val Loss: 0.7351 - Val F1: 0.5127\n",
      "Epoch 5/50 - Train Loss: 0.7635 - Train F1: 0.4649 - Val Loss: 0.6777 - Val F1: 0.5525\n",
      "Epoch 6/50 - Train Loss: 0.7269 - Train F1: 0.5303 - Val Loss: 0.6462 - Val F1: 0.6219\n",
      "Epoch 7/50 - Train Loss: 0.6914 - Train F1: 0.5627 - Val Loss: 0.6242 - Val F1: 0.6131\n",
      "Epoch 8/50 - Train Loss: 0.6543 - Train F1: 0.6150 - Val Loss: 0.6066 - Val F1: 0.5860\n",
      "Epoch 9/50 - Train Loss: 0.6303 - Train F1: 0.6278 - Val Loss: 0.5689 - Val F1: 0.6845\n",
      "Epoch 10/50 - Train Loss: 0.6258 - Train F1: 0.6345 - Val Loss: 0.5930 - Val F1: 0.6345\n",
      "Epoch 11/50 - Train Loss: 0.6069 - Train F1: 0.6465 - Val Loss: 0.5706 - Val F1: 0.6736\n",
      "Epoch 12/50 - Train Loss: 0.5895 - Train F1: 0.6572 - Val Loss: 0.5456 - Val F1: 0.6987\n",
      "Epoch 13/50 - Train Loss: 0.5835 - Train F1: 0.6623 - Val Loss: 0.5317 - Val F1: 0.7052\n",
      "Epoch 14/50 - Train Loss: 0.5595 - Train F1: 0.6841 - Val Loss: 0.5373 - Val F1: 0.6985\n",
      "Epoch 15/50 - Train Loss: 0.5518 - Train F1: 0.6993 - Val Loss: 0.5346 - Val F1: 0.6763\n",
      "Epoch 16/50 - Train Loss: 0.5515 - Train F1: 0.7004 - Val Loss: 0.5111 - Val F1: 0.7163\n",
      "Epoch 17/50 - Train Loss: 0.5333 - Train F1: 0.7111 - Val Loss: 0.5186 - Val F1: 0.7228\n",
      "Epoch 18/50 - Train Loss: 0.5340 - Train F1: 0.7052 - Val Loss: 0.4963 - Val F1: 0.7273\n",
      "Epoch 19/50 - Train Loss: 0.5345 - Train F1: 0.7088 - Val Loss: 0.5206 - Val F1: 0.7284\n",
      "Epoch 20/50 - Train Loss: 0.5059 - Train F1: 0.7278 - Val Loss: 0.4903 - Val F1: 0.7372\n",
      "Epoch 21/50 - Train Loss: 0.5065 - Train F1: 0.7275 - Val Loss: 0.4904 - Val F1: 0.7333\n",
      "Epoch 22/50 - Train Loss: 0.5055 - Train F1: 0.7183 - Val Loss: 0.4778 - Val F1: 0.7358\n",
      "Epoch 23/50 - Train Loss: 0.4881 - Train F1: 0.7473 - Val Loss: 0.4700 - Val F1: 0.7506\n",
      "Epoch 24/50 - Train Loss: 0.4903 - Train F1: 0.7445 - Val Loss: 0.4770 - Val F1: 0.7611\n",
      "Epoch 25/50 - Train Loss: 0.4876 - Train F1: 0.7416 - Val Loss: 0.4880 - Val F1: 0.7391\n",
      "Epoch 26/50 - Train Loss: 0.4785 - Train F1: 0.7555 - Val Loss: 0.4726 - Val F1: 0.7663\n",
      "Epoch 27/50 - Train Loss: 0.4720 - Train F1: 0.7639 - Val Loss: 0.4684 - Val F1: 0.7527\n",
      "Epoch 28/50 - Train Loss: 0.4695 - Train F1: 0.7599 - Val Loss: 0.4652 - Val F1: 0.7588\n",
      "Epoch 29/50 - Train Loss: 0.4678 - Train F1: 0.7569 - Val Loss: 0.5145 - Val F1: 0.7125\n",
      "Epoch 30/50 - Train Loss: 0.4518 - Train F1: 0.7727 - Val Loss: 0.4723 - Val F1: 0.7642\n",
      "Epoch 31/50 - Train Loss: 0.4608 - Train F1: 0.7661 - Val Loss: 0.4645 - Val F1: 0.7565\n",
      "Epoch 32/50 - Train Loss: 0.4607 - Train F1: 0.7626 - Val Loss: 0.4568 - Val F1: 0.7900\n",
      "Epoch 33/50 - Train Loss: 0.4536 - Train F1: 0.7718 - Val Loss: 0.4738 - Val F1: 0.7679\n",
      "Epoch 34/50 - Train Loss: 0.4475 - Train F1: 0.7723 - Val Loss: 0.4688 - Val F1: 0.7635\n",
      "Epoch 35/50 - Train Loss: 0.4377 - Train F1: 0.7866 - Val Loss: 0.4717 - Val F1: 0.7713\n",
      "Epoch 36/50 - Train Loss: 0.4335 - Train F1: 0.7845 - Val Loss: 0.4753 - Val F1: 0.7628\n",
      "Epoch 37/50 - Train Loss: 0.4313 - Train F1: 0.7905 - Val Loss: 0.4999 - Val F1: 0.7214\n",
      "\n",
      "Early stopping triggered at epoch 37\n",
      "üìä Confusion Matrix:\n",
      " [[346   4  12   1]\n",
      " [  7  38   9   0]\n",
      " [ 60  18  96   2]\n",
      " [  7   0   2  13]]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ECGNet(\n",
    "    num_classes=4,\n",
    "    n_fft=512,\n",
    "    hop_length=256,\n",
    "    conv1_padding=1,\n",
    "    conv2_padding=1,\n",
    "    conv1_kernel=3,\n",
    "    conv2_kernel=3,\n",
    "    lstm_num_layers=1,\n",
    "    conv1_channels=32,\n",
    "    conv2_channels=32,\n",
    "    lst_hidden_size=128,\n",
    "    dropout=0.1,\n",
    "    signal_length=X_train.shape[1],\n",
    "    device=device,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "trainer = Trainer(model, optimizer, criterion, augment_data=True, device=device)\n",
    "\n",
    "history = trainer.fit(train_loader, val_loader, epochs=50)\n",
    "\n",
    "train_loss, train_f1 = trainer.evaluate(train_loader)\n",
    "\n",
    "val_loss, val_f1 = trainer.evaluate(val_loader)\n",
    "\n",
    "\n",
    "cm, report = trainer.detailed_metrics(val_loader, class_names=[\"class_0\", \"class_1\", \"class_2\", \"class_3\"])\n",
    "print(\"üìä Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349ffdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÑ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     class_0     0.8238    0.9532    0.8838       363\n",
      "     class_1     0.6333    0.7037    0.6667        54\n",
      "     class_2     0.8067    0.5455    0.6508       176\n",
      "     class_3     0.8125    0.5909    0.6842        22\n",
      "\n",
      "    accuracy                         0.8016       615\n",
      "   macro avg     0.7691    0.6983    0.7214       615\n",
      "weighted avg     0.8018    0.8016    0.7909       615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm, report = trainer.detailed_metrics(val_loader, class_names=[\"class_0\", \"class_1\", \"class_2\", \"class_3\"])\n",
    "print(\"\\nüìÑ Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a78551ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'learning_rate': 0.001, 'hidden_channels': [64, 128, 128, 128], 'dropout': 0.1, 'num_levels': 3}\n",
      "Epoch 1/5 | Train Loss: 0.9341 | Train F1: 0.2667 | Val Loss: 0.8246 | Val F1: 0.3874\n",
      "Epoch 2/5 | Train Loss: 0.7934 | Train F1: 0.3967 | Val Loss: 0.7065 | Val F1: 0.4543\n",
      "Epoch 3/5 | Train Loss: 0.7096 | Train F1: 0.4864 | Val Loss: 0.6723 | Val F1: 0.5496\n",
      "Epoch 4/5 | Train Loss: 0.6553 | Train F1: 0.5339 | Val Loss: 0.6016 | Val F1: 0.6278\n",
      "Epoch 5/5 | Train Loss: 0.6234 | Train F1: 0.5856 | Val Loss: 0.6080 | Val F1: 0.6162\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'learning_rate': 0.001, 'hidden_channels': [64, 128, 128, 128], 'dropout': 0.1, 'num_levels': 4}\n",
      "Epoch 1/5 | Train Loss: 0.9239 | Train F1: 0.2720 | Val Loss: 0.8040 | Val F1: 0.3220\n",
      "Epoch 2/5 | Train Loss: 0.7996 | Train F1: 0.4021 | Val Loss: 0.7239 | Val F1: 0.4130\n",
      "Epoch 3/5 | Train Loss: 0.7336 | Train F1: 0.4836 | Val Loss: 0.6804 | Val F1: 0.4839\n",
      "Epoch 4/5 | Train Loss: 0.6871 | Train F1: 0.5301 | Val Loss: 0.6770 | Val F1: 0.4842\n",
      "Epoch 5/5 | Train Loss: 0.6300 | Train F1: 0.5822 | Val Loss: 0.6284 | Val F1: 0.5835\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'learning_rate': 0.001, 'hidden_channels': [64, 128, 128, 128], 'dropout': 0.1, 'num_levels': 3}\n",
      "Epoch 1/5 | Train Loss: 0.9244 | Train F1: 0.2742 | Val Loss: 0.8530 | Val F1: 0.3459\n",
      "Epoch 2/5 | Train Loss: 0.8157 | Train F1: 0.3817 | Val Loss: 0.7535 | Val F1: 0.5241\n",
      "Epoch 3/5 | Train Loss: 0.7473 | Train F1: 0.4591 | Val Loss: 0.7428 | Val F1: 0.4567\n",
      "Epoch 4/5 | Train Loss: 0.6611 | Train F1: 0.5476 | Val Loss: 0.6472 | Val F1: 0.5783\n",
      "Epoch 5/5 | Train Loss: 0.6290 | Train F1: 0.5788 | Val Loss: 0.5963 | Val F1: 0.6277\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'learning_rate': 0.001, 'hidden_channels': [64, 128, 128, 128], 'dropout': 0.1, 'num_levels': 4}\n",
      "Epoch 1/5 | Train Loss: 0.9211 | Train F1: 0.2833 | Val Loss: 0.8305 | Val F1: 0.3116\n",
      "Epoch 2/5 | Train Loss: 0.8280 | Train F1: 0.3848 | Val Loss: 0.7826 | Val F1: 0.3326\n",
      "Epoch 3/5 | Train Loss: 0.7560 | Train F1: 0.4749 | Val Loss: 0.7012 | Val F1: 0.4682\n",
      "Epoch 4/5 | Train Loss: 0.6812 | Train F1: 0.5566 | Val Loss: 0.6955 | Val F1: 0.4621\n",
      "Epoch 5/5 | Train Loss: 0.6421 | Train F1: 0.5635 | Val Loss: 0.6444 | Val F1: 0.5591\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'learning_rate': 0.001, 'hidden_channels': [64, 128, 128, 128], 'dropout': 0.2, 'num_levels': 3}\n",
      "Epoch 1/5 | Train Loss: 0.9335 | Train F1: 0.2793 | Val Loss: 0.8327 | Val F1: 0.3091\n",
      "Epoch 2/5 | Train Loss: 0.8098 | Train F1: 0.3799 | Val Loss: 0.7355 | Val F1: 0.4112\n",
      "Epoch 3/5 | Train Loss: 0.7440 | Train F1: 0.4684 | Val Loss: 0.7087 | Val F1: 0.4640\n",
      "Epoch 4/5 | Train Loss: 0.6936 | Train F1: 0.4902 | Val Loss: 0.6456 | Val F1: 0.4534\n",
      "Epoch 5/5 | Train Loss: 0.6571 | Train F1: 0.5443 | Val Loss: 0.7058 | Val F1: 0.4488\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'learning_rate': 0.001, 'hidden_channels': [64, 128, 128, 128], 'dropout': 0.2, 'num_levels': 4}\n",
      "Epoch 1/5 | Train Loss: 0.9438 | Train F1: 0.2647 | Val Loss: 0.8714 | Val F1: 0.3051\n",
      "Epoch 2/5 | Train Loss: 0.8385 | Train F1: 0.3730 | Val Loss: 0.8892 | Val F1: 0.3345\n",
      "Epoch 3/5 | Train Loss: 0.7560 | Train F1: 0.4510 | Val Loss: 0.7152 | Val F1: 0.4937\n",
      "Epoch 4/5 | Train Loss: 0.7000 | Train F1: 0.5016 | Val Loss: 0.6830 | Val F1: 0.5716\n",
      "Epoch 5/5 | Train Loss: 0.6657 | Train F1: 0.5494 | Val Loss: 0.6245 | Val F1: 0.5107\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'learning_rate': 0.001, 'hidden_channels': [64, 128, 128, 128], 'dropout': 0.2, 'num_levels': 3}\n",
      "Epoch 1/5 | Train Loss: 0.9487 | Train F1: 0.2620 | Val Loss: 0.8689 | Val F1: 0.3180\n",
      "Epoch 2/5 | Train Loss: 0.8164 | Train F1: 0.3641 | Val Loss: 0.7621 | Val F1: 0.4148\n",
      "Epoch 3/5 | Train Loss: 0.7348 | Train F1: 0.4636 | Val Loss: 0.7733 | Val F1: 0.3640\n",
      "Epoch 4/5 | Train Loss: 0.6955 | Train F1: 0.5020 | Val Loss: 0.7064 | Val F1: 0.4337\n",
      "Epoch 5/5 | Train Loss: 0.6525 | Train F1: 0.5549 | Val Loss: 0.6460 | Val F1: 0.5471\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'learning_rate': 0.001, 'hidden_channels': [64, 128, 128, 128], 'dropout': 0.2, 'num_levels': 4}\n",
      "Epoch 1/5 | Train Loss: 0.9479 | Train F1: 0.2549 | Val Loss: 0.8360 | Val F1: 0.2966\n",
      "Epoch 2/5 | Train Loss: 0.8216 | Train F1: 0.3912 | Val Loss: 0.7499 | Val F1: 0.4273\n",
      "Epoch 3/5 | Train Loss: 0.7589 | Train F1: 0.4700 | Val Loss: 0.7425 | Val F1: 0.6033\n",
      "Epoch 4/5 | Train Loss: 0.6949 | Train F1: 0.5385 | Val Loss: 0.6442 | Val F1: 0.5090\n",
      "Epoch 5/5 | Train Loss: 0.6433 | Train F1: 0.5678 | Val Loss: 0.6137 | Val F1: 0.6384\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'learning_rate': 0.001, 'hidden_channels': [64, 128, 128, 128], 'dropout': 0.3, 'num_levels': 3}\n",
      "Epoch 1/5 | Train Loss: 0.9188 | Train F1: 0.2817 | Val Loss: 0.8224 | Val F1: 0.3171\n",
      "Epoch 2/5 | Train Loss: 0.8093 | Train F1: 0.3955 | Val Loss: 0.7287 | Val F1: 0.3979\n",
      "Epoch 3/5 | Train Loss: 0.7654 | Train F1: 0.4398 | Val Loss: 0.6928 | Val F1: 0.5150\n",
      "Epoch 4/5 | Train Loss: 0.7051 | Train F1: 0.4878 | Val Loss: 0.6547 | Val F1: 0.5371\n",
      "Epoch 5/5 | Train Loss: 0.6656 | Train F1: 0.5407 | Val Loss: 0.6753 | Val F1: 0.5966\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'learning_rate': 0.001, 'hidden_channels': [64, 128, 128, 128], 'dropout': 0.3, 'num_levels': 4}\n",
      "Epoch 1/5 | Train Loss: 0.9124 | Train F1: 0.2799 | Val Loss: 0.8001 | Val F1: 0.3291\n",
      "Epoch 2/5 | Train Loss: 0.8119 | Train F1: 0.3840 | Val Loss: 0.7779 | Val F1: 0.3527\n",
      "Epoch 3/5 | Train Loss: 0.7505 | Train F1: 0.4729 | Val Loss: 0.7387 | Val F1: 0.4297\n",
      "Epoch 4/5 | Train Loss: 0.6890 | Train F1: 0.5199 | Val Loss: 0.7044 | Val F1: 0.4489\n",
      "Epoch 5/5 | Train Loss: 0.6676 | Train F1: 0.5443 | Val Loss: 0.7231 | Val F1: 0.5709\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'learning_rate': 0.001, 'hidden_channels': [64, 128, 128, 128], 'dropout': 0.3, 'num_levels': 3}\n",
      "Epoch 1/5 | Train Loss: 0.9459 | Train F1: 0.2623 | Val Loss: 0.8209 | Val F1: 0.3047\n",
      "Epoch 2/5 | Train Loss: 0.8059 | Train F1: 0.3796 | Val Loss: 0.8575 | Val F1: 0.4350\n",
      "Epoch 3/5 | Train Loss: 0.7474 | Train F1: 0.4622 | Val Loss: 0.7115 | Val F1: 0.4810\n",
      "Epoch 4/5 | Train Loss: 0.7172 | Train F1: 0.5049 | Val Loss: 0.6919 | Val F1: 0.5650\n",
      "Epoch 5/5 | Train Loss: 0.6908 | Train F1: 0.5254 | Val Loss: 0.6950 | Val F1: 0.4887\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'learning_rate': 0.001, 'hidden_channels': [64, 128, 128, 128], 'dropout': 0.3, 'num_levels': 4}\n",
      "Epoch 1/5 | Train Loss: 0.9489 | Train F1: 0.2636 | Val Loss: 0.8637 | Val F1: 0.3248\n",
      "Epoch 2/5 | Train Loss: 0.8233 | Train F1: 0.3938 | Val Loss: 0.7620 | Val F1: 0.4717\n",
      "Epoch 3/5 | Train Loss: 0.7530 | Train F1: 0.4861 | Val Loss: 0.6950 | Val F1: 0.4210\n",
      "Epoch 4/5 | Train Loss: 0.7076 | Train F1: 0.5285 | Val Loss: 0.6875 | Val F1: 0.4739\n",
      "Epoch 5/5 | Train Loss: 0.6463 | Train F1: 0.5507 | Val Loss: 0.6944 | Val F1: 0.5316\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'learning_rate': 0.001, 'hidden_channels': [128, 128, 128, 128], 'dropout': 0.1, 'num_levels': 3}\n",
      "Epoch 1/5 | Train Loss: 0.9415 | Train F1: 0.2950 | Val Loss: 0.8218 | Val F1: 0.3525\n",
      "Epoch 2/5 | Train Loss: 0.8029 | Train F1: 0.3921 | Val Loss: 0.8645 | Val F1: 0.4353\n",
      "Epoch 3/5 | Train Loss: 0.7225 | Train F1: 0.4714 | Val Loss: 0.6564 | Val F1: 0.4510\n",
      "Epoch 4/5 | Train Loss: 0.6600 | Train F1: 0.5417 | Val Loss: 0.6253 | Val F1: 0.5993\n",
      "Epoch 5/5 | Train Loss: 0.6254 | Train F1: 0.5874 | Val Loss: 0.5888 | Val F1: 0.6004\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'learning_rate': 0.001, 'hidden_channels': [128, 128, 128, 128], 'dropout': 0.1, 'num_levels': 4}\n",
      "Epoch 1/5 | Train Loss: 0.9311 | Train F1: 0.3115 | Val Loss: 0.8214 | Val F1: 0.3277\n",
      "Epoch 2/5 | Train Loss: 0.8019 | Train F1: 0.3895 | Val Loss: 0.7321 | Val F1: 0.4468\n",
      "Epoch 3/5 | Train Loss: 0.7252 | Train F1: 0.4832 | Val Loss: 0.6655 | Val F1: 0.5031\n",
      "Epoch 4/5 | Train Loss: 0.6599 | Train F1: 0.5253 | Val Loss: 0.6168 | Val F1: 0.4996\n",
      "Epoch 5/5 | Train Loss: 0.6322 | Train F1: 0.5816 | Val Loss: 0.6310 | Val F1: 0.4562\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'learning_rate': 0.001, 'hidden_channels': [128, 128, 128, 128], 'dropout': 0.1, 'num_levels': 3}\n",
      "Epoch 1/5 | Train Loss: 0.9889 | Train F1: 0.2766 | Val Loss: 0.8496 | Val F1: 0.3088\n",
      "Epoch 2/5 | Train Loss: 0.8340 | Train F1: 0.3547 | Val Loss: 0.7750 | Val F1: 0.3600\n",
      "Epoch 3/5 | Train Loss: 0.7792 | Train F1: 0.4525 | Val Loss: 0.8082 | Val F1: 0.4404\n",
      "Epoch 4/5 | Train Loss: 0.7209 | Train F1: 0.5023 | Val Loss: 0.6988 | Val F1: 0.4259\n",
      "Epoch 5/5 | Train Loss: 0.6632 | Train F1: 0.5355 | Val Loss: 0.6746 | Val F1: 0.6458\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'learning_rate': 0.001, 'hidden_channels': [128, 128, 128, 128], 'dropout': 0.1, 'num_levels': 4}\n",
      "Epoch 1/5 | Train Loss: 0.9651 | Train F1: 0.2805 | Val Loss: 0.8184 | Val F1: 0.3376\n",
      "Epoch 2/5 | Train Loss: 0.7919 | Train F1: 0.4109 | Val Loss: 0.7747 | Val F1: 0.4583\n",
      "Epoch 3/5 | Train Loss: 0.7141 | Train F1: 0.4945 | Val Loss: 0.6733 | Val F1: 0.4800\n",
      "Epoch 4/5 | Train Loss: 0.6513 | Train F1: 0.5563 | Val Loss: 0.6922 | Val F1: 0.4717\n",
      "Epoch 5/5 | Train Loss: 0.6085 | Train F1: 0.6095 | Val Loss: 0.6696 | Val F1: 0.5996\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'learning_rate': 0.001, 'hidden_channels': [128, 128, 128, 128], 'dropout': 0.2, 'num_levels': 3}\n",
      "Epoch 1/5 | Train Loss: 0.9659 | Train F1: 0.2819 | Val Loss: 0.8310 | Val F1: 0.3529\n",
      "Epoch 2/5 | Train Loss: 0.7995 | Train F1: 0.4141 | Val Loss: 0.7505 | Val F1: 0.5611\n",
      "Epoch 3/5 | Train Loss: 0.7308 | Train F1: 0.4918 | Val Loss: 0.7372 | Val F1: 0.3510\n",
      "Epoch 4/5 | Train Loss: 0.6789 | Train F1: 0.5042 | Val Loss: 0.6813 | Val F1: 0.6039\n",
      "Epoch 5/5 | Train Loss: 0.6507 | Train F1: 0.5658 | Val Loss: 0.7113 | Val F1: 0.4978\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'learning_rate': 0.001, 'hidden_channels': [128, 128, 128, 128], 'dropout': 0.2, 'num_levels': 4}\n",
      "Epoch 1/5 | Train Loss: 0.9451 | Train F1: 0.3044 | Val Loss: 0.8237 | Val F1: 0.3202\n",
      "Epoch 2/5 | Train Loss: 0.8040 | Train F1: 0.4129 | Val Loss: 0.7726 | Val F1: 0.4676\n",
      "Epoch 3/5 | Train Loss: 0.7315 | Train F1: 0.4888 | Val Loss: 0.6671 | Val F1: 0.4649\n",
      "Epoch 4/5 | Train Loss: 0.6803 | Train F1: 0.5294 | Val Loss: 0.6201 | Val F1: 0.5424\n",
      "Epoch 5/5 | Train Loss: 0.6659 | Train F1: 0.5476 | Val Loss: 0.7297 | Val F1: 0.4930\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'learning_rate': 0.001, 'hidden_channels': [128, 128, 128, 128], 'dropout': 0.2, 'num_levels': 3}\n",
      "Epoch 1/5 | Train Loss: 0.9484 | Train F1: 0.2847 | Val Loss: 0.8865 | Val F1: 0.3020\n",
      "Epoch 2/5 | Train Loss: 0.8187 | Train F1: 0.3939 | Val Loss: 0.8444 | Val F1: 0.4086\n",
      "Epoch 3/5 | Train Loss: 0.7764 | Train F1: 0.4436 | Val Loss: 0.7220 | Val F1: 0.4582\n",
      "Epoch 4/5 | Train Loss: 0.6883 | Train F1: 0.5073 | Val Loss: 0.7637 | Val F1: 0.4120\n",
      "Epoch 5/5 | Train Loss: 0.6561 | Train F1: 0.5479 | Val Loss: 0.6421 | Val F1: 0.5347\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'learning_rate': 0.001, 'hidden_channels': [128, 128, 128, 128], 'dropout': 0.2, 'num_levels': 4}\n",
      "Epoch 1/5 | Train Loss: 0.9596 | Train F1: 0.2794 | Val Loss: 0.8258 | Val F1: 0.3812\n",
      "Epoch 2/5 | Train Loss: 0.8089 | Train F1: 0.3805 | Val Loss: 0.7771 | Val F1: 0.4204\n",
      "Epoch 3/5 | Train Loss: 0.7801 | Train F1: 0.4311 | Val Loss: 0.7110 | Val F1: 0.4060\n",
      "Epoch 4/5 | Train Loss: 0.7010 | Train F1: 0.5123 | Val Loss: 0.6771 | Val F1: 0.3828\n",
      "Epoch 5/5 | Train Loss: 0.6647 | Train F1: 0.5465 | Val Loss: 0.6670 | Val F1: 0.5752\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'learning_rate': 0.001, 'hidden_channels': [128, 128, 128, 128], 'dropout': 0.3, 'num_levels': 3}\n",
      "Epoch 1/5 | Train Loss: 0.9505 | Train F1: 0.2813 | Val Loss: 0.9207 | Val F1: 0.2196\n",
      "Epoch 2/5 | Train Loss: 0.8208 | Train F1: 0.3835 | Val Loss: 0.7896 | Val F1: 0.3839\n",
      "Epoch 3/5 | Train Loss: 0.7569 | Train F1: 0.4452 | Val Loss: 0.6662 | Val F1: 0.4614\n",
      "Epoch 4/5 | Train Loss: 0.7138 | Train F1: 0.4832 | Val Loss: 0.6663 | Val F1: 0.5182\n",
      "Epoch 5/5 | Train Loss: 0.6687 | Train F1: 0.5396 | Val Loss: 0.6735 | Val F1: 0.4855\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 3, 'learning_rate': 0.001, 'hidden_channels': [128, 128, 128, 128], 'dropout': 0.3, 'num_levels': 4}\n",
      "Epoch 1/5 | Train Loss: 0.9895 | Train F1: 0.2858 | Val Loss: 0.9410 | Val F1: 0.3923\n",
      "Epoch 2/5 | Train Loss: 0.8437 | Train F1: 0.3521 | Val Loss: 0.8888 | Val F1: 0.3499\n",
      "Epoch 3/5 | Train Loss: 0.7595 | Train F1: 0.4400 | Val Loss: 0.7359 | Val F1: 0.4442\n",
      "Epoch 4/5 | Train Loss: 0.7017 | Train F1: 0.4735 | Val Loss: 0.6824 | Val F1: 0.4796\n",
      "Epoch 5/5 | Train Loss: 0.6656 | Train F1: 0.5394 | Val Loss: 0.7082 | Val F1: 0.4560\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'learning_rate': 0.001, 'hidden_channels': [128, 128, 128, 128], 'dropout': 0.3, 'num_levels': 3}\n",
      "Epoch 1/5 | Train Loss: 0.9388 | Train F1: 0.2997 | Val Loss: 0.8148 | Val F1: 0.3940\n",
      "Epoch 2/5 | Train Loss: 0.7828 | Train F1: 0.4223 | Val Loss: 0.7682 | Val F1: 0.4925\n",
      "Epoch 3/5 | Train Loss: 0.7598 | Train F1: 0.4681 | Val Loss: 0.7351 | Val F1: 0.3611\n",
      "Epoch 4/5 | Train Loss: 0.7115 | Train F1: 0.4942 | Val Loss: 0.6820 | Val F1: 0.5231\n",
      "Epoch 5/5 | Train Loss: 0.6855 | Train F1: 0.5367 | Val Loss: 0.6307 | Val F1: 0.5841\n",
      "\n",
      "üîß Training with config: {'num_classes': 4, 'n_fft': 256, 'hop_length': 128, 'kernel_size': 5, 'learning_rate': 0.001, 'hidden_channels': [128, 128, 128, 128], 'dropout': 0.3, 'num_levels': 4}\n",
      "Epoch 1/5 | Train Loss: 1.0050 | Train F1: 0.2575 | Val Loss: 0.9399 | Val F1: 0.2265\n",
      "Epoch 2/5 | Train Loss: 0.8421 | Train F1: 0.3606 | Val Loss: 0.8176 | Val F1: 0.4402\n",
      "Epoch 3/5 | Train Loss: 0.7753 | Train F1: 0.4434 | Val Loss: 0.7975 | Val F1: 0.3840\n",
      "Epoch 4/5 | Train Loss: 0.7112 | Train F1: 0.5154 | Val Loss: 0.6408 | Val F1: 0.5266\n",
      "Epoch 5/5 | Train Loss: 0.6590 | Train F1: 0.5524 | Val Loss: 0.6267 | Val F1: 0.5267\n",
      "\n",
      "üèÜ Top 3 configurations:\n",
      "\n",
      "#1 - Val F1: 0.6458\n",
      "Hyperparameters:\n",
      "  num_classes: 4\n",
      "  n_fft: 256\n",
      "  hop_length: 128\n",
      "  kernel_size: 5\n",
      "  learning_rate: 0.001\n",
      "  hidden_channels: [128, 128, 128, 128]\n",
      "  dropout: 0.1\n",
      "  num_levels: 3\n",
      "Train F1: 0.5355 | Val Loss: 0.6746\n",
      "\n",
      "#2 - Val F1: 0.6384\n",
      "Hyperparameters:\n",
      "  num_classes: 4\n",
      "  n_fft: 256\n",
      "  hop_length: 128\n",
      "  kernel_size: 5\n",
      "  learning_rate: 0.001\n",
      "  hidden_channels: [64, 128, 128, 128]\n",
      "  dropout: 0.2\n",
      "  num_levels: 4\n",
      "Train F1: 0.5678 | Val Loss: 0.6137\n",
      "\n",
      "#3 - Val F1: 0.6278\n",
      "Hyperparameters:\n",
      "  num_classes: 4\n",
      "  n_fft: 256\n",
      "  hop_length: 128\n",
      "  kernel_size: 3\n",
      "  learning_rate: 0.001\n",
      "  hidden_channels: [64, 128, 128, 128]\n",
      "  dropout: 0.1\n",
      "  num_levels: 3\n",
      "Train F1: 0.5339 | Val Loss: 0.6016\n"
     ]
    }
   ],
   "source": [
    "from src.models.model_2 import TCN_STFT_Classifier\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    # Configuraciones donde len(hidden_channels) == num_levels\n",
    "    \n",
    "        'hidden_channels': [[64,128,128,128],[128,128,128,128]],\n",
    "    'dropout': [0.1, 0.2, 0.3],\n",
    "    'kernel_size': [3, 5],\n",
    "    'num_levels': [3,4]\n",
    "}\n",
    "\n",
    "\n",
    "fixed = {\n",
    "    \"num_classes\": 4,\n",
    "    \"n_fft\": 256,\n",
    "    \"hop_length\": 128,\n",
    "    \"kernel_size\": 3,\n",
    "    \"learning_rate\" : .001,\n",
    "}\n",
    "\n",
    "results = hyperparameter_search(\n",
    "    TCN_STFT_Classifier,\n",
    "    param_grid,\n",
    "    fixed,\n",
    "    device=device,\n",
    "    epochs=5,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    augmented_data = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5028a46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toby_\\AMLS\\venv\\Lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.9240 - Train F1: 0.3045 - Val Loss: 0.8471 - Val F1: 0.3358\n",
      "Epoch 2/50 - Train Loss: 0.7996 - Train F1: 0.4088 - Val Loss: 0.7389 - Val F1: 0.3822\n",
      "Epoch 3/50 - Train Loss: 0.7313 - Train F1: 0.4693 - Val Loss: 0.6555 - Val F1: 0.5936\n",
      "Epoch 4/50 - Train Loss: 0.6751 - Train F1: 0.5524 - Val Loss: 0.6319 - Val F1: 0.6317\n",
      "Epoch 5/50 - Train Loss: 0.6157 - Train F1: 0.5948 - Val Loss: 0.6183 - Val F1: 0.6315\n",
      "Epoch 6/50 - Train Loss: 0.5908 - Train F1: 0.6158 - Val Loss: 0.5669 - Val F1: 0.6596\n",
      "Epoch 7/50 - Train Loss: 0.5812 - Train F1: 0.6365 - Val Loss: 0.5825 - Val F1: 0.6478\n",
      "Epoch 8/50 - Train Loss: 0.5544 - Train F1: 0.6596 - Val Loss: 0.5485 - Val F1: 0.6885\n",
      "Epoch 9/50 - Train Loss: 0.5540 - Train F1: 0.6548 - Val Loss: 0.5741 - Val F1: 0.6793\n",
      "Epoch 10/50 - Train Loss: 0.5542 - Train F1: 0.6469 - Val Loss: 0.5419 - Val F1: 0.6842\n",
      "Epoch 11/50 - Train Loss: 0.5400 - Train F1: 0.6639 - Val Loss: 0.5479 - Val F1: 0.6924\n",
      "Epoch 12/50 - Train Loss: 0.5264 - Train F1: 0.6886 - Val Loss: 0.6569 - Val F1: 0.6069\n",
      "Epoch 13/50 - Train Loss: 0.5295 - Train F1: 0.6693 - Val Loss: 0.5087 - Val F1: 0.7078\n",
      "Epoch 14/50 - Train Loss: 0.5005 - Train F1: 0.6962 - Val Loss: 0.5290 - Val F1: 0.7323\n",
      "Epoch 15/50 - Train Loss: 0.5092 - Train F1: 0.6915 - Val Loss: 0.5671 - Val F1: 0.7007\n",
      "Epoch 16/50 - Train Loss: 0.4958 - Train F1: 0.7082 - Val Loss: 0.5546 - Val F1: 0.6845\n",
      "Epoch 17/50 - Train Loss: 0.4807 - Train F1: 0.7203 - Val Loss: 0.5133 - Val F1: 0.7161\n",
      "Epoch 18/50 - Train Loss: 0.4679 - Train F1: 0.7220 - Val Loss: 0.5150 - Val F1: 0.6746\n",
      "\n",
      "Early stopping triggered at epoch 18\n",
      "0.6740469932556152 0.6745858192443848\n",
      "üìä Confusion Matrix:\n",
      " [[347   2  14   0]\n",
      " [  7  27  20   0]\n",
      " [ 54  12 107   3]\n",
      " [  9   0   3  10]]\n",
      "\n",
      "üìÑ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     class_0     0.8321    0.9559    0.8897       363\n",
      "     class_1     0.6585    0.5000    0.5684        54\n",
      "     class_2     0.7431    0.6080    0.6687       176\n",
      "     class_3     0.7692    0.4545    0.5714        22\n",
      "\n",
      "    accuracy                         0.7984       615\n",
      "   macro avg     0.7507    0.6296    0.6746       615\n",
      "weighted avg     0.7891    0.7984    0.7869       615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.models.model_2 import TCN_STFT_Classifier\n",
    "from src.models.model_trainer import Trainer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = TCN_STFT_Classifier(\n",
    "    num_classes=4,\n",
    "    hop_length = 128,\n",
    "    n_fft = 256,\n",
    "    kernel_size = 5, \n",
    "    hidden_channels=  [128, 128, 128, 128],\n",
    "    dropout = 0.1,\n",
    "    num_levels = 3,\n",
    "    device=device,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "trainer = Trainer(model, optimizer, criterion, device=device, augment_data = True)\n",
    "\n",
    "history = trainer.fit(train_loader, val_loader, epochs=50)\n",
    "\n",
    "train_loss, train_f1 = trainer.evaluate(train_loader)\n",
    "\n",
    "val_loss, val_f1 = trainer.evaluate(val_loader)\n",
    "\n",
    "print(train_f1, val_f1)\n",
    "\n",
    "cm, report = trainer.detailed_metrics(val_loader, class_names=[\"class_0\", \"class_1\", \"class_2\", \"class_3\"])\n",
    "print(\"\\nüìÑ Classification Report:\\n\", report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
